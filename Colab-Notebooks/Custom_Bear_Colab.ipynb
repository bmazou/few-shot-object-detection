{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A1QTpWHAnNa",
        "outputId": "ea035c3c-4ef7-4fcd-be29-8ddbb5db2805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-12233ac7-0827-4074-7e85-9da18093f928)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWt7gRy4bxFg",
        "outputId": "55984e00-5a99-4793-9448-933717631df3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'custom_fsdet' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://gitlab.mff.cuni.cz/mazoureb/custom_fsdet.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC5xqPGqe6Qi",
        "outputId": "d791c3af-dc70-4384-8b39-ec34c185aaeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.6.0 torchvision==0.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd2GQXC3fAVS",
        "outputId": "e2bb89ba-0110-4411-89a3-23731b8423ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/index.html\n",
            "Requirement already satisfied: detectron2==0.3 in /usr/local/lib/python3.7/dist-packages (0.3+cu102)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (3.2.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (1.3.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (2.8.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (2.0.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (0.8.10)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (4.64.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (1.1.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (1.3.0)\n",
            "Requirement already satisfied: fvcore>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (0.1.2.post20201213)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (0.16.0)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.3) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.2->detectron2==0.3) (6.0)\n",
            "Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.2->detectron2==0.3) (0.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.2->detectron2==0.3) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2==0.3) (4.1.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.2->fvcore>=0.1.2->detectron2==0.3) (2.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.3) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.3) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.3) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.3) (1.15.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (1.47.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.3) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.3) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.3) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.3) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.3) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->detectron2==0.3) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.3) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.3) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.3) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install detectron2==0.3 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.6/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xuLCmPHfC_p",
        "outputId": "c57c5c45-f100-4dc7-91bb-86a82516a4ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/custom_fsdet\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (7.1.2)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (2.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (4.6.0.66)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.5.3)\n",
            "Requirement already satisfied: fvcore==0.1.2.post20201213 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (0.1.2.post20201213)\n",
            "Requirement already satisfied: iopath>=0.1.2 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.2.post20201213->-r requirements.txt (line 15)) (0.1.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore==0.1.2.post20201213->-r requirements.txt (line 15)) (6.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.2->fvcore==0.1.2.post20201213->-r requirements.txt (line 15)) (2.5.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from iopath>=0.1.2->fvcore==0.1.2.post20201213->-r requirements.txt (line 15)) (4.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (3.4.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 11)) (1.47.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 11)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 11)) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 11)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 11)) (3.2.0)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis->-r requirements.txt (line 13)) (0.29.30)\n"
          ]
        }
      ],
      "source": [
        "%cd custom_fsdet\n",
        "!python3 -m pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUFODUhKezdh",
        "outputId": "6bfbfcad-a300-4dad-d44a-cdef31767a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Mounted at /content/gdrive\n",
            "/content/custom_fsdet\n"
          ]
        }
      ],
      "source": [
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd custom_fsdet/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/gdrive/MyDrive/fsdet-v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrvQevsJPSCE",
        "outputId": "0db338c5-ecf6-4db0-d1e0-75688e9caa46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.yaml\n",
            "custom\n",
            "events.out.tfevents.1658691737.38026711c178.1681.0\n",
            "events.out.tfevents.1658732575.321faf86f6fe.663.0\n",
            "events.out.tfevents.1658738132.2f167e10b4d7.677.0\n",
            "events.out.tfevents.1659035890.f68983988098.632.0\n",
            "events.out.tfevents.1659036248.f68983988098.723.0\n",
            "jsons\n",
            "last_checkpoint\n",
            "log.txt\n",
            "metrics.json\n",
            "model_reset_surgery.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neEV9uj3Y4Gh"
      },
      "source": [
        "### Few shot training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxOQPrSaSme3",
        "outputId": "ace22457-92ef-4a11-e567-cc47d4a0b800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jul 28 19:31:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v8AVi0-jtKV",
        "outputId": "b844ec7c-ce31-43cc-fe17-700be951a0e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "** fvcore version of PathManager will be deprecated soon. **\n",
            "** Please migrate to the version in iopath repo. **\n",
            "https://github.com/facebookresearch/iopath \n",
            "\n",
            "Command Line Args: Namespace(config_file='configs/Custom-Bear/base_training_cfg.yaml', dist_url='tcp://127.0.0.1:49152', end_iter=-1, eval_all=False, eval_during_train=False, eval_iter=-1, eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=None, resume=False, start_iter=-1)\n",
            "\u001b[32m[07/28 19:34:35 detectron2]: \u001b[0mRank of current process: 0. World size: 1\n",
            "\u001b[32m[07/28 19:34:35 detectron2]: \u001b[0mCommand line arguments: Namespace(config_file='configs/Custom-Bear/base_training_cfg.yaml', dist_url='tcp://127.0.0.1:49152', end_iter=-1, eval_all=False, eval_during_train=False, eval_iter=-1, eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=None, resume=False, start_iter=-1)\n",
            "\u001b[32m[07/28 19:34:35 detectron2]: \u001b[0mContents of args.config_file=configs/Custom-Bear/base_training_cfg.yaml:\n",
            "_BASE_: \"../Base-RCNN-FPN.yaml\"\n",
            "MODEL:\n",
            "  WEIGHTS: \"detectron2://ImageNetPretrained/MSRA/R-101.pkl\"\n",
            "  MASK_ON: False\n",
            "  RESNETS:\n",
            "    DEPTH: 101\n",
            "  ROI_HEADS:\n",
            "    NUM_CLASSES: 4\n",
            "INPUT:\n",
            "  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
            "  MIN_SIZE_TEST: 800\n",
            "DATASETS:\n",
            "  TRAIN: ('custom_bear_all',) # <-- modify this\n",
            "  TEST: ('custom_bear_novel',) # <-- modify this\n",
            "SOLVER:\n",
            "  STEPS: (12000, 16000)\n",
            "  MAX_ITER: 18000\n",
            "  WARMUP_ITERS: 100\n",
            "  CHECKPOINT_PERIOD: 1500\n",
            "  IMS_PER_BATCH: 8\n",
            "OUTPUT_DIR: \"/content/gdrive/MyDrive/fsdet-v\"\n",
            "\u001b[32m[07/28 19:34:35 detectron2]: \u001b[0mFull config saved to /content/gdrive/MyDrive/fsdet-v/config.yaml\n",
            "\u001b[32m[07/28 19:34:35 d2.utils.env]: \u001b[0mUsing a generated random seed 35133044\n",
            "\u001b[32m[07/28 19:34:39 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 460 images left.\n",
            "\u001b[32m[07/28 19:34:39 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|    bear    | 12           |    car     | 305          |    cat     | 170          |\n",
            "|    dog     | 198          |            |              |            |              |\n",
            "|   total    | 685          |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[07/28 19:34:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[07/28 19:34:39 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[07/28 19:34:39 d2.data.common]: \u001b[0mSerializing 460 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[07/28 19:34:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.12 MiB\n",
            "\u001b[32m[07/28 19:34:41 fvcore.common.checkpoint]: \u001b[0mLoading checkpoint from detectron2://ImageNetPretrained/MSRA/R-101.pkl\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mRemapping C2 weights ......\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv1.norm.bias            loaded from res2_0_branch2a_bn_beta           of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv1.norm.running_mean    loaded from res2_0_branch2a_bn_running_mean   of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv1.norm.running_var     loaded from res2_0_branch2a_bn_running_var    of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv1.norm.weight          loaded from res2_0_branch2a_bn_gamma          of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv1.weight               loaded from res2_0_branch2a_w                 of shape (64, 64, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv2.norm.bias            loaded from res2_0_branch2b_bn_beta           of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv2.norm.running_mean    loaded from res2_0_branch2b_bn_running_mean   of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv2.norm.running_var     loaded from res2_0_branch2b_bn_running_var    of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv2.norm.weight          loaded from res2_0_branch2b_bn_gamma          of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv2.weight               loaded from res2_0_branch2b_w                 of shape (64, 64, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv3.norm.bias            loaded from res2_0_branch2c_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv3.norm.running_mean    loaded from res2_0_branch2c_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv3.norm.running_var     loaded from res2_0_branch2c_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv3.norm.weight          loaded from res2_0_branch2c_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.conv3.weight               loaded from res2_0_branch2c_w                 of shape (256, 64, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.shortcut.norm.bias         loaded from res2_0_branch1_bn_beta            of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.shortcut.norm.running_mean loaded from res2_0_branch1_bn_running_mean    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.shortcut.norm.running_var  loaded from res2_0_branch1_bn_running_var     of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.shortcut.norm.weight       loaded from res2_0_branch1_bn_gamma           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.0.shortcut.weight            loaded from res2_0_branch1_w                  of shape (256, 64, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv1.norm.bias            loaded from res2_1_branch2a_bn_beta           of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv1.norm.running_mean    loaded from res2_1_branch2a_bn_running_mean   of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv1.norm.running_var     loaded from res2_1_branch2a_bn_running_var    of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv1.norm.weight          loaded from res2_1_branch2a_bn_gamma          of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv1.weight               loaded from res2_1_branch2a_w                 of shape (64, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv2.norm.bias            loaded from res2_1_branch2b_bn_beta           of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv2.norm.running_mean    loaded from res2_1_branch2b_bn_running_mean   of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv2.norm.running_var     loaded from res2_1_branch2b_bn_running_var    of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv2.norm.weight          loaded from res2_1_branch2b_bn_gamma          of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv2.weight               loaded from res2_1_branch2b_w                 of shape (64, 64, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv3.norm.bias            loaded from res2_1_branch2c_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv3.norm.running_mean    loaded from res2_1_branch2c_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv3.norm.running_var     loaded from res2_1_branch2c_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv3.norm.weight          loaded from res2_1_branch2c_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.1.conv3.weight               loaded from res2_1_branch2c_w                 of shape (256, 64, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv1.norm.bias            loaded from res2_2_branch2a_bn_beta           of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv1.norm.running_mean    loaded from res2_2_branch2a_bn_running_mean   of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv1.norm.running_var     loaded from res2_2_branch2a_bn_running_var    of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv1.norm.weight          loaded from res2_2_branch2a_bn_gamma          of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv1.weight               loaded from res2_2_branch2a_w                 of shape (64, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv2.norm.bias            loaded from res2_2_branch2b_bn_beta           of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv2.norm.running_mean    loaded from res2_2_branch2b_bn_running_mean   of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv2.norm.running_var     loaded from res2_2_branch2b_bn_running_var    of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv2.norm.weight          loaded from res2_2_branch2b_bn_gamma          of shape (64,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv2.weight               loaded from res2_2_branch2b_w                 of shape (64, 64, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv3.norm.bias            loaded from res2_2_branch2c_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv3.norm.running_mean    loaded from res2_2_branch2c_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv3.norm.running_var     loaded from res2_2_branch2c_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv3.norm.weight          loaded from res2_2_branch2c_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res2.2.conv3.weight               loaded from res2_2_branch2c_w                 of shape (256, 64, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv1.norm.bias            loaded from res3_0_branch2a_bn_beta           of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv1.norm.running_mean    loaded from res3_0_branch2a_bn_running_mean   of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv1.norm.running_var     loaded from res3_0_branch2a_bn_running_var    of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv1.norm.weight          loaded from res3_0_branch2a_bn_gamma          of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv1.weight               loaded from res3_0_branch2a_w                 of shape (128, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv2.norm.bias            loaded from res3_0_branch2b_bn_beta           of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv2.norm.running_mean    loaded from res3_0_branch2b_bn_running_mean   of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv2.norm.running_var     loaded from res3_0_branch2b_bn_running_var    of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv2.norm.weight          loaded from res3_0_branch2b_bn_gamma          of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv2.weight               loaded from res3_0_branch2b_w                 of shape (128, 128, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv3.norm.bias            loaded from res3_0_branch2c_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv3.norm.running_mean    loaded from res3_0_branch2c_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv3.norm.running_var     loaded from res3_0_branch2c_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv3.norm.weight          loaded from res3_0_branch2c_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.conv3.weight               loaded from res3_0_branch2c_w                 of shape (512, 128, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.shortcut.norm.bias         loaded from res3_0_branch1_bn_beta            of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.shortcut.norm.running_mean loaded from res3_0_branch1_bn_running_mean    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.shortcut.norm.running_var  loaded from res3_0_branch1_bn_running_var     of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.shortcut.norm.weight       loaded from res3_0_branch1_bn_gamma           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.0.shortcut.weight            loaded from res3_0_branch1_w                  of shape (512, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv1.norm.bias            loaded from res3_1_branch2a_bn_beta           of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv1.norm.running_mean    loaded from res3_1_branch2a_bn_running_mean   of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv1.norm.running_var     loaded from res3_1_branch2a_bn_running_var    of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv1.norm.weight          loaded from res3_1_branch2a_bn_gamma          of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv1.weight               loaded from res3_1_branch2a_w                 of shape (128, 512, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv2.norm.bias            loaded from res3_1_branch2b_bn_beta           of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv2.norm.running_mean    loaded from res3_1_branch2b_bn_running_mean   of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv2.norm.running_var     loaded from res3_1_branch2b_bn_running_var    of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv2.norm.weight          loaded from res3_1_branch2b_bn_gamma          of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv2.weight               loaded from res3_1_branch2b_w                 of shape (128, 128, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv3.norm.bias            loaded from res3_1_branch2c_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv3.norm.running_mean    loaded from res3_1_branch2c_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv3.norm.running_var     loaded from res3_1_branch2c_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv3.norm.weight          loaded from res3_1_branch2c_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.1.conv3.weight               loaded from res3_1_branch2c_w                 of shape (512, 128, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv1.norm.bias            loaded from res3_2_branch2a_bn_beta           of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv1.norm.running_mean    loaded from res3_2_branch2a_bn_running_mean   of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv1.norm.running_var     loaded from res3_2_branch2a_bn_running_var    of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv1.norm.weight          loaded from res3_2_branch2a_bn_gamma          of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv1.weight               loaded from res3_2_branch2a_w                 of shape (128, 512, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv2.norm.bias            loaded from res3_2_branch2b_bn_beta           of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv2.norm.running_mean    loaded from res3_2_branch2b_bn_running_mean   of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv2.norm.running_var     loaded from res3_2_branch2b_bn_running_var    of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv2.norm.weight          loaded from res3_2_branch2b_bn_gamma          of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv2.weight               loaded from res3_2_branch2b_w                 of shape (128, 128, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv3.norm.bias            loaded from res3_2_branch2c_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv3.norm.running_mean    loaded from res3_2_branch2c_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv3.norm.running_var     loaded from res3_2_branch2c_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv3.norm.weight          loaded from res3_2_branch2c_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.2.conv3.weight               loaded from res3_2_branch2c_w                 of shape (512, 128, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv1.norm.bias            loaded from res3_3_branch2a_bn_beta           of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv1.norm.running_mean    loaded from res3_3_branch2a_bn_running_mean   of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv1.norm.running_var     loaded from res3_3_branch2a_bn_running_var    of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv1.norm.weight          loaded from res3_3_branch2a_bn_gamma          of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv1.weight               loaded from res3_3_branch2a_w                 of shape (128, 512, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv2.norm.bias            loaded from res3_3_branch2b_bn_beta           of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv2.norm.running_mean    loaded from res3_3_branch2b_bn_running_mean   of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv2.norm.running_var     loaded from res3_3_branch2b_bn_running_var    of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv2.norm.weight          loaded from res3_3_branch2b_bn_gamma          of shape (128,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv2.weight               loaded from res3_3_branch2b_w                 of shape (128, 128, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv3.norm.bias            loaded from res3_3_branch2c_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv3.norm.running_mean    loaded from res3_3_branch2c_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv3.norm.running_var     loaded from res3_3_branch2c_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv3.norm.weight          loaded from res3_3_branch2c_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res3.3.conv3.weight               loaded from res3_3_branch2c_w                 of shape (512, 128, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv1.norm.bias            loaded from res4_0_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv1.norm.running_mean    loaded from res4_0_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv1.norm.running_var     loaded from res4_0_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv1.norm.weight          loaded from res4_0_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv1.weight               loaded from res4_0_branch2a_w                 of shape (256, 512, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv2.norm.bias            loaded from res4_0_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv2.norm.running_mean    loaded from res4_0_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv2.norm.running_var     loaded from res4_0_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv2.norm.weight          loaded from res4_0_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv2.weight               loaded from res4_0_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv3.norm.bias            loaded from res4_0_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv3.norm.running_mean    loaded from res4_0_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv3.norm.running_var     loaded from res4_0_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv3.norm.weight          loaded from res4_0_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.conv3.weight               loaded from res4_0_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.shortcut.norm.bias         loaded from res4_0_branch1_bn_beta            of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.shortcut.norm.running_mean loaded from res4_0_branch1_bn_running_mean    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.shortcut.norm.running_var  loaded from res4_0_branch1_bn_running_var     of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.shortcut.norm.weight       loaded from res4_0_branch1_bn_gamma           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.0.shortcut.weight            loaded from res4_0_branch1_w                  of shape (1024, 512, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv1.norm.bias            loaded from res4_1_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv1.norm.running_mean    loaded from res4_1_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv1.norm.running_var     loaded from res4_1_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv1.norm.weight          loaded from res4_1_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv1.weight               loaded from res4_1_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv2.norm.bias            loaded from res4_1_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv2.norm.running_mean    loaded from res4_1_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv2.norm.running_var     loaded from res4_1_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv2.norm.weight          loaded from res4_1_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv2.weight               loaded from res4_1_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv3.norm.bias            loaded from res4_1_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv3.norm.running_mean    loaded from res4_1_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv3.norm.running_var     loaded from res4_1_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv3.norm.weight          loaded from res4_1_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.1.conv3.weight               loaded from res4_1_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv1.norm.bias           loaded from res4_10_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv1.norm.running_mean   loaded from res4_10_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv1.norm.running_var    loaded from res4_10_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv1.norm.weight         loaded from res4_10_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv1.weight              loaded from res4_10_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv2.norm.bias           loaded from res4_10_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv2.norm.running_mean   loaded from res4_10_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv2.norm.running_var    loaded from res4_10_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv2.norm.weight         loaded from res4_10_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv2.weight              loaded from res4_10_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv3.norm.bias           loaded from res4_10_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv3.norm.running_mean   loaded from res4_10_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv3.norm.running_var    loaded from res4_10_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv3.norm.weight         loaded from res4_10_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.10.conv3.weight              loaded from res4_10_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv1.norm.bias           loaded from res4_11_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv1.norm.running_mean   loaded from res4_11_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv1.norm.running_var    loaded from res4_11_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv1.norm.weight         loaded from res4_11_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv1.weight              loaded from res4_11_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv2.norm.bias           loaded from res4_11_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv2.norm.running_mean   loaded from res4_11_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv2.norm.running_var    loaded from res4_11_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv2.norm.weight         loaded from res4_11_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv2.weight              loaded from res4_11_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv3.norm.bias           loaded from res4_11_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv3.norm.running_mean   loaded from res4_11_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv3.norm.running_var    loaded from res4_11_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv3.norm.weight         loaded from res4_11_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.11.conv3.weight              loaded from res4_11_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv1.norm.bias           loaded from res4_12_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv1.norm.running_mean   loaded from res4_12_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv1.norm.running_var    loaded from res4_12_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv1.norm.weight         loaded from res4_12_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv1.weight              loaded from res4_12_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv2.norm.bias           loaded from res4_12_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv2.norm.running_mean   loaded from res4_12_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv2.norm.running_var    loaded from res4_12_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv2.norm.weight         loaded from res4_12_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv2.weight              loaded from res4_12_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv3.norm.bias           loaded from res4_12_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv3.norm.running_mean   loaded from res4_12_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv3.norm.running_var    loaded from res4_12_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv3.norm.weight         loaded from res4_12_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.12.conv3.weight              loaded from res4_12_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv1.norm.bias           loaded from res4_13_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv1.norm.running_mean   loaded from res4_13_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv1.norm.running_var    loaded from res4_13_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv1.norm.weight         loaded from res4_13_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv1.weight              loaded from res4_13_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv2.norm.bias           loaded from res4_13_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv2.norm.running_mean   loaded from res4_13_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv2.norm.running_var    loaded from res4_13_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv2.norm.weight         loaded from res4_13_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv2.weight              loaded from res4_13_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv3.norm.bias           loaded from res4_13_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv3.norm.running_mean   loaded from res4_13_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv3.norm.running_var    loaded from res4_13_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv3.norm.weight         loaded from res4_13_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.13.conv3.weight              loaded from res4_13_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv1.norm.bias           loaded from res4_14_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv1.norm.running_mean   loaded from res4_14_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv1.norm.running_var    loaded from res4_14_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv1.norm.weight         loaded from res4_14_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv1.weight              loaded from res4_14_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv2.norm.bias           loaded from res4_14_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv2.norm.running_mean   loaded from res4_14_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv2.norm.running_var    loaded from res4_14_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv2.norm.weight         loaded from res4_14_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv2.weight              loaded from res4_14_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv3.norm.bias           loaded from res4_14_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv3.norm.running_mean   loaded from res4_14_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv3.norm.running_var    loaded from res4_14_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv3.norm.weight         loaded from res4_14_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.14.conv3.weight              loaded from res4_14_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv1.norm.bias           loaded from res4_15_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv1.norm.running_mean   loaded from res4_15_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv1.norm.running_var    loaded from res4_15_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv1.norm.weight         loaded from res4_15_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv1.weight              loaded from res4_15_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv2.norm.bias           loaded from res4_15_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv2.norm.running_mean   loaded from res4_15_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv2.norm.running_var    loaded from res4_15_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv2.norm.weight         loaded from res4_15_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv2.weight              loaded from res4_15_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv3.norm.bias           loaded from res4_15_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv3.norm.running_mean   loaded from res4_15_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv3.norm.running_var    loaded from res4_15_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv3.norm.weight         loaded from res4_15_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.15.conv3.weight              loaded from res4_15_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv1.norm.bias           loaded from res4_16_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv1.norm.running_mean   loaded from res4_16_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv1.norm.running_var    loaded from res4_16_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv1.norm.weight         loaded from res4_16_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv1.weight              loaded from res4_16_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv2.norm.bias           loaded from res4_16_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv2.norm.running_mean   loaded from res4_16_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv2.norm.running_var    loaded from res4_16_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv2.norm.weight         loaded from res4_16_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv2.weight              loaded from res4_16_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv3.norm.bias           loaded from res4_16_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv3.norm.running_mean   loaded from res4_16_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv3.norm.running_var    loaded from res4_16_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv3.norm.weight         loaded from res4_16_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.16.conv3.weight              loaded from res4_16_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv1.norm.bias           loaded from res4_17_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv1.norm.running_mean   loaded from res4_17_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv1.norm.running_var    loaded from res4_17_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv1.norm.weight         loaded from res4_17_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv1.weight              loaded from res4_17_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv2.norm.bias           loaded from res4_17_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv2.norm.running_mean   loaded from res4_17_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv2.norm.running_var    loaded from res4_17_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv2.norm.weight         loaded from res4_17_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv2.weight              loaded from res4_17_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv3.norm.bias           loaded from res4_17_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv3.norm.running_mean   loaded from res4_17_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv3.norm.running_var    loaded from res4_17_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv3.norm.weight         loaded from res4_17_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.17.conv3.weight              loaded from res4_17_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv1.norm.bias           loaded from res4_18_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv1.norm.running_mean   loaded from res4_18_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv1.norm.running_var    loaded from res4_18_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv1.norm.weight         loaded from res4_18_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv1.weight              loaded from res4_18_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv2.norm.bias           loaded from res4_18_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv2.norm.running_mean   loaded from res4_18_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv2.norm.running_var    loaded from res4_18_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv2.norm.weight         loaded from res4_18_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv2.weight              loaded from res4_18_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv3.norm.bias           loaded from res4_18_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv3.norm.running_mean   loaded from res4_18_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv3.norm.running_var    loaded from res4_18_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv3.norm.weight         loaded from res4_18_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.18.conv3.weight              loaded from res4_18_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv1.norm.bias           loaded from res4_19_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv1.norm.running_mean   loaded from res4_19_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv1.norm.running_var    loaded from res4_19_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv1.norm.weight         loaded from res4_19_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv1.weight              loaded from res4_19_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv2.norm.bias           loaded from res4_19_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv2.norm.running_mean   loaded from res4_19_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv2.norm.running_var    loaded from res4_19_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv2.norm.weight         loaded from res4_19_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv2.weight              loaded from res4_19_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv3.norm.bias           loaded from res4_19_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv3.norm.running_mean   loaded from res4_19_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv3.norm.running_var    loaded from res4_19_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv3.norm.weight         loaded from res4_19_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.19.conv3.weight              loaded from res4_19_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv1.norm.bias            loaded from res4_2_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv1.norm.running_mean    loaded from res4_2_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv1.norm.running_var     loaded from res4_2_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv1.norm.weight          loaded from res4_2_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv1.weight               loaded from res4_2_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv2.norm.bias            loaded from res4_2_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv2.norm.running_mean    loaded from res4_2_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv2.norm.running_var     loaded from res4_2_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv2.norm.weight          loaded from res4_2_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv2.weight               loaded from res4_2_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv3.norm.bias            loaded from res4_2_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv3.norm.running_mean    loaded from res4_2_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv3.norm.running_var     loaded from res4_2_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv3.norm.weight          loaded from res4_2_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.2.conv3.weight               loaded from res4_2_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv1.norm.bias           loaded from res4_20_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv1.norm.running_mean   loaded from res4_20_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv1.norm.running_var    loaded from res4_20_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv1.norm.weight         loaded from res4_20_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv1.weight              loaded from res4_20_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv2.norm.bias           loaded from res4_20_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv2.norm.running_mean   loaded from res4_20_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv2.norm.running_var    loaded from res4_20_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv2.norm.weight         loaded from res4_20_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv2.weight              loaded from res4_20_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv3.norm.bias           loaded from res4_20_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv3.norm.running_mean   loaded from res4_20_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv3.norm.running_var    loaded from res4_20_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv3.norm.weight         loaded from res4_20_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.20.conv3.weight              loaded from res4_20_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv1.norm.bias           loaded from res4_21_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv1.norm.running_mean   loaded from res4_21_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv1.norm.running_var    loaded from res4_21_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv1.norm.weight         loaded from res4_21_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv1.weight              loaded from res4_21_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv2.norm.bias           loaded from res4_21_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv2.norm.running_mean   loaded from res4_21_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv2.norm.running_var    loaded from res4_21_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv2.norm.weight         loaded from res4_21_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv2.weight              loaded from res4_21_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv3.norm.bias           loaded from res4_21_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv3.norm.running_mean   loaded from res4_21_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv3.norm.running_var    loaded from res4_21_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv3.norm.weight         loaded from res4_21_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.21.conv3.weight              loaded from res4_21_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv1.norm.bias           loaded from res4_22_branch2a_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv1.norm.running_mean   loaded from res4_22_branch2a_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv1.norm.running_var    loaded from res4_22_branch2a_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv1.norm.weight         loaded from res4_22_branch2a_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv1.weight              loaded from res4_22_branch2a_w                of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv2.norm.bias           loaded from res4_22_branch2b_bn_beta          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv2.norm.running_mean   loaded from res4_22_branch2b_bn_running_mean  of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv2.norm.running_var    loaded from res4_22_branch2b_bn_running_var   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv2.norm.weight         loaded from res4_22_branch2b_bn_gamma         of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv2.weight              loaded from res4_22_branch2b_w                of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv3.norm.bias           loaded from res4_22_branch2c_bn_beta          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv3.norm.running_mean   loaded from res4_22_branch2c_bn_running_mean  of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv3.norm.running_var    loaded from res4_22_branch2c_bn_running_var   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv3.norm.weight         loaded from res4_22_branch2c_bn_gamma         of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.22.conv3.weight              loaded from res4_22_branch2c_w                of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv1.norm.bias            loaded from res4_3_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv1.norm.running_mean    loaded from res4_3_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv1.norm.running_var     loaded from res4_3_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv1.norm.weight          loaded from res4_3_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv1.weight               loaded from res4_3_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv2.norm.bias            loaded from res4_3_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv2.norm.running_mean    loaded from res4_3_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv2.norm.running_var     loaded from res4_3_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv2.norm.weight          loaded from res4_3_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv2.weight               loaded from res4_3_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv3.norm.bias            loaded from res4_3_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv3.norm.running_mean    loaded from res4_3_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv3.norm.running_var     loaded from res4_3_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv3.norm.weight          loaded from res4_3_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.3.conv3.weight               loaded from res4_3_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv1.norm.bias            loaded from res4_4_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv1.norm.running_mean    loaded from res4_4_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv1.norm.running_var     loaded from res4_4_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv1.norm.weight          loaded from res4_4_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv1.weight               loaded from res4_4_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv2.norm.bias            loaded from res4_4_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv2.norm.running_mean    loaded from res4_4_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv2.norm.running_var     loaded from res4_4_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv2.norm.weight          loaded from res4_4_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv2.weight               loaded from res4_4_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv3.norm.bias            loaded from res4_4_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv3.norm.running_mean    loaded from res4_4_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv3.norm.running_var     loaded from res4_4_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv3.norm.weight          loaded from res4_4_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.4.conv3.weight               loaded from res4_4_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv1.norm.bias            loaded from res4_5_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv1.norm.running_mean    loaded from res4_5_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv1.norm.running_var     loaded from res4_5_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv1.norm.weight          loaded from res4_5_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv1.weight               loaded from res4_5_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv2.norm.bias            loaded from res4_5_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv2.norm.running_mean    loaded from res4_5_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv2.norm.running_var     loaded from res4_5_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv2.norm.weight          loaded from res4_5_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv2.weight               loaded from res4_5_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv3.norm.bias            loaded from res4_5_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv3.norm.running_mean    loaded from res4_5_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv3.norm.running_var     loaded from res4_5_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv3.norm.weight          loaded from res4_5_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.5.conv3.weight               loaded from res4_5_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv1.norm.bias            loaded from res4_6_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv1.norm.running_mean    loaded from res4_6_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv1.norm.running_var     loaded from res4_6_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv1.norm.weight          loaded from res4_6_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv1.weight               loaded from res4_6_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv2.norm.bias            loaded from res4_6_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv2.norm.running_mean    loaded from res4_6_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv2.norm.running_var     loaded from res4_6_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv2.norm.weight          loaded from res4_6_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv2.weight               loaded from res4_6_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv3.norm.bias            loaded from res4_6_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv3.norm.running_mean    loaded from res4_6_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv3.norm.running_var     loaded from res4_6_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv3.norm.weight          loaded from res4_6_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.6.conv3.weight               loaded from res4_6_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv1.norm.bias            loaded from res4_7_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv1.norm.running_mean    loaded from res4_7_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv1.norm.running_var     loaded from res4_7_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv1.norm.weight          loaded from res4_7_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv1.weight               loaded from res4_7_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv2.norm.bias            loaded from res4_7_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv2.norm.running_mean    loaded from res4_7_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv2.norm.running_var     loaded from res4_7_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv2.norm.weight          loaded from res4_7_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv2.weight               loaded from res4_7_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv3.norm.bias            loaded from res4_7_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv3.norm.running_mean    loaded from res4_7_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv3.norm.running_var     loaded from res4_7_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv3.norm.weight          loaded from res4_7_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.7.conv3.weight               loaded from res4_7_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv1.norm.bias            loaded from res4_8_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv1.norm.running_mean    loaded from res4_8_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv1.norm.running_var     loaded from res4_8_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv1.norm.weight          loaded from res4_8_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv1.weight               loaded from res4_8_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv2.norm.bias            loaded from res4_8_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv2.norm.running_mean    loaded from res4_8_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv2.norm.running_var     loaded from res4_8_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv2.norm.weight          loaded from res4_8_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv2.weight               loaded from res4_8_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv3.norm.bias            loaded from res4_8_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv3.norm.running_mean    loaded from res4_8_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv3.norm.running_var     loaded from res4_8_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv3.norm.weight          loaded from res4_8_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.8.conv3.weight               loaded from res4_8_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv1.norm.bias            loaded from res4_9_branch2a_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv1.norm.running_mean    loaded from res4_9_branch2a_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv1.norm.running_var     loaded from res4_9_branch2a_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv1.norm.weight          loaded from res4_9_branch2a_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv1.weight               loaded from res4_9_branch2a_w                 of shape (256, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv2.norm.bias            loaded from res4_9_branch2b_bn_beta           of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv2.norm.running_mean    loaded from res4_9_branch2b_bn_running_mean   of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv2.norm.running_var     loaded from res4_9_branch2b_bn_running_var    of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv2.norm.weight          loaded from res4_9_branch2b_bn_gamma          of shape (256,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv2.weight               loaded from res4_9_branch2b_w                 of shape (256, 256, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv3.norm.bias            loaded from res4_9_branch2c_bn_beta           of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv3.norm.running_mean    loaded from res4_9_branch2c_bn_running_mean   of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv3.norm.running_var     loaded from res4_9_branch2c_bn_running_var    of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv3.norm.weight          loaded from res4_9_branch2c_bn_gamma          of shape (1024,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res4.9.conv3.weight               loaded from res4_9_branch2c_w                 of shape (1024, 256, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv1.norm.bias            loaded from res5_0_branch2a_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv1.norm.running_mean    loaded from res5_0_branch2a_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv1.norm.running_var     loaded from res5_0_branch2a_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv1.norm.weight          loaded from res5_0_branch2a_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv1.weight               loaded from res5_0_branch2a_w                 of shape (512, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv2.norm.bias            loaded from res5_0_branch2b_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv2.norm.running_mean    loaded from res5_0_branch2b_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv2.norm.running_var     loaded from res5_0_branch2b_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv2.norm.weight          loaded from res5_0_branch2b_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv2.weight               loaded from res5_0_branch2b_w                 of shape (512, 512, 3, 3)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv3.norm.bias            loaded from res5_0_branch2c_bn_beta           of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv3.norm.running_mean    loaded from res5_0_branch2c_bn_running_mean   of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv3.norm.running_var     loaded from res5_0_branch2c_bn_running_var    of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv3.norm.weight          loaded from res5_0_branch2c_bn_gamma          of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.conv3.weight               loaded from res5_0_branch2c_w                 of shape (2048, 512, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.shortcut.norm.bias         loaded from res5_0_branch1_bn_beta            of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.shortcut.norm.running_mean loaded from res5_0_branch1_bn_running_mean    of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.shortcut.norm.running_var  loaded from res5_0_branch1_bn_running_var     of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.shortcut.norm.weight       loaded from res5_0_branch1_bn_gamma           of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.0.shortcut.weight            loaded from res5_0_branch1_w                  of shape (2048, 1024, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv1.norm.bias            loaded from res5_1_branch2a_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv1.norm.running_mean    loaded from res5_1_branch2a_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv1.norm.running_var     loaded from res5_1_branch2a_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv1.norm.weight          loaded from res5_1_branch2a_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv1.weight               loaded from res5_1_branch2a_w                 of shape (512, 2048, 1, 1)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv2.norm.bias            loaded from res5_1_branch2b_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv2.norm.running_mean    loaded from res5_1_branch2b_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:41 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv2.norm.running_var     loaded from res5_1_branch2b_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv2.norm.weight          loaded from res5_1_branch2b_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv2.weight               loaded from res5_1_branch2b_w                 of shape (512, 512, 3, 3)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv3.norm.bias            loaded from res5_1_branch2c_bn_beta           of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv3.norm.running_mean    loaded from res5_1_branch2c_bn_running_mean   of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv3.norm.running_var     loaded from res5_1_branch2c_bn_running_var    of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv3.norm.weight          loaded from res5_1_branch2c_bn_gamma          of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.1.conv3.weight               loaded from res5_1_branch2c_w                 of shape (2048, 512, 1, 1)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv1.norm.bias            loaded from res5_2_branch2a_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv1.norm.running_mean    loaded from res5_2_branch2a_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv1.norm.running_var     loaded from res5_2_branch2a_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv1.norm.weight          loaded from res5_2_branch2a_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv1.weight               loaded from res5_2_branch2a_w                 of shape (512, 2048, 1, 1)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv2.norm.bias            loaded from res5_2_branch2b_bn_beta           of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv2.norm.running_mean    loaded from res5_2_branch2b_bn_running_mean   of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv2.norm.running_var     loaded from res5_2_branch2b_bn_running_var    of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv2.norm.weight          loaded from res5_2_branch2b_bn_gamma          of shape (512,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv2.weight               loaded from res5_2_branch2b_w                 of shape (512, 512, 3, 3)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv3.norm.bias            loaded from res5_2_branch2c_bn_beta           of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv3.norm.running_mean    loaded from res5_2_branch2c_bn_running_mean   of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv3.norm.running_var     loaded from res5_2_branch2c_bn_running_var    of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv3.norm.weight          loaded from res5_2_branch2c_bn_gamma          of shape (2048,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.res5.2.conv3.weight               loaded from res5_2_branch2c_w                 of shape (2048, 512, 1, 1)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.stem.conv1.norm.bias              loaded from res_conv1_bn_beta                 of shape (64,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.stem.conv1.norm.running_mean      loaded from res_conv1_bn_running_mean         of shape (64,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.stem.conv1.norm.running_var       loaded from res_conv1_bn_running_var          of shape (64,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.stem.conv1.norm.weight            loaded from res_conv1_bn_gamma                of shape (64,)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mbackbone.bottom_up.stem.conv1.weight                 loaded from conv1_w                           of shape (64, 3, 7, 7)\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mSome model parameters or buffers are not found in the checkpoint:\n",
            "  \u001b[34mbackbone.fpn_lateral2.{bias, weight}\u001b[0m\n",
            "  \u001b[34mbackbone.fpn_lateral3.{bias, weight}\u001b[0m\n",
            "  \u001b[34mbackbone.fpn_lateral4.{bias, weight}\u001b[0m\n",
            "  \u001b[34mbackbone.fpn_lateral5.{bias, weight}\u001b[0m\n",
            "  \u001b[34mbackbone.fpn_output2.{bias, weight}\u001b[0m\n",
            "  \u001b[34mbackbone.fpn_output3.{bias, weight}\u001b[0m\n",
            "  \u001b[34mbackbone.fpn_output4.{bias, weight}\u001b[0m\n",
            "  \u001b[34mbackbone.fpn_output5.{bias, weight}\u001b[0m\n",
            "  \u001b[34mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n",
            "  \u001b[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}\u001b[0m\n",
            "  \u001b[34mproposal_generator.rpn_head.conv.{bias, weight}\u001b[0m\n",
            "  \u001b[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}\u001b[0m\n",
            "  \u001b[34mroi_heads.box_head.fc1.{bias, weight}\u001b[0m\n",
            "  \u001b[34mroi_heads.box_head.fc2.{bias, weight}\u001b[0m\n",
            "  \u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "  \u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[32m[07/28 19:34:42 d2.checkpoint.c2_model_loading]: \u001b[0mThe checkpoint state_dict contains keys that are not used by the model:\n",
            "  \u001b[35mfc1000_b\u001b[0m\n",
            "  \u001b[35mfc1000_w\u001b[0m\n",
            "\u001b[32m[07/28 19:34:42 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
            "/content/custom_fsdet/fsdet/modeling/roi_heads/fast_rcnn.py:198: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  num_fg = fg_inds.nonzero().numel()\n",
            "\u001b[32m[07/28 19:35:32 d2.utils.events]: \u001b[0m eta: 12:19:27  iter: 19  total_loss: 0.6492  loss_cls: 0.2165  loss_box_reg: 0.06229  loss_rpn_cls: 0.3083  loss_rpn_loc: 0.03669  time: 2.5191  data_time: 0.1256  lr: 0.0038162  max_mem: 12496M\n",
            "\u001b[32m[07/28 19:36:24 d2.utils.events]: \u001b[0m eta: 12:33:34  iter: 39  total_loss: 0.4014  loss_cls: 0.1713  loss_box_reg: 0.1296  loss_rpn_cls: 0.06299  loss_rpn_loc: 0.03765  time: 2.5631  data_time: 0.1112  lr: 0.0078122  max_mem: 12496M\n",
            "\u001b[32m[07/28 19:37:19 d2.utils.events]: \u001b[0m eta: 13:10:47  iter: 59  total_loss: 0.3482  loss_cls: 0.1289  loss_box_reg: 0.1366  loss_rpn_cls: 0.04901  loss_rpn_loc: 0.03723  time: 2.6202  data_time: 0.0928  lr: 0.011808  max_mem: 12496M\n",
            "\u001b[32m[07/28 19:38:14 d2.utils.events]: \u001b[0m eta: 13:14:32  iter: 79  total_loss: 0.3279  loss_cls: 0.1336  loss_box_reg: 0.13  loss_rpn_cls: 0.04099  loss_rpn_loc: 0.02241  time: 2.6532  data_time: 0.1237  lr: 0.015804  max_mem: 12496M\n",
            "\u001b[32m[07/28 19:39:13 d2.utils.events]: \u001b[0m eta: 13:26:42  iter: 99  total_loss: 0.3653  loss_cls: 0.1411  loss_box_reg: 0.1512  loss_rpn_cls: 0.03543  loss_rpn_loc: 0.0302  time: 2.7150  data_time: 0.1181  lr: 0.0198  max_mem: 12496M\n",
            "\u001b[32m[07/28 19:40:11 d2.utils.events]: \u001b[0m eta: 13:42:37  iter: 119  total_loss: 0.3669  loss_cls: 0.1418  loss_box_reg: 0.1542  loss_rpn_cls: 0.0265  loss_rpn_loc: 0.04334  time: 2.7481  data_time: 0.1077  lr: 0.02  max_mem: 12496M\n",
            "\u001b[32m[07/28 19:41:09 d2.utils.events]: \u001b[0m eta: 13:45:48  iter: 139  total_loss: 0.3024  loss_cls: 0.12  loss_box_reg: 0.1354  loss_rpn_cls: 0.02224  loss_rpn_loc: 0.02323  time: 2.7656  data_time: 0.1053  lr: 0.02  max_mem: 12496M\n",
            "\u001b[32m[07/28 19:42:09 d2.utils.events]: \u001b[0m eta: 13:57:18  iter: 159  total_loss: 0.3108  loss_cls: 0.124  loss_box_reg: 0.1272  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.03152  time: 2.7955  data_time: 0.0871  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:43:07 d2.utils.events]: \u001b[0m eta: 13:58:41  iter: 179  total_loss: 0.3082  loss_cls: 0.1107  loss_box_reg: 0.1374  loss_rpn_cls: 0.02295  loss_rpn_loc: 0.02039  time: 2.8084  data_time: 0.0918  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:44:05 d2.utils.events]: \u001b[0m eta: 13:58:33  iter: 199  total_loss: 0.3188  loss_cls: 0.1235  loss_box_reg: 0.1325  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.03293  time: 2.8184  data_time: 0.1103  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:45:02 d2.utils.events]: \u001b[0m eta: 13:58:02  iter: 219  total_loss: 0.2868  loss_cls: 0.09357  loss_box_reg: 0.1203  loss_rpn_cls: 0.02525  loss_rpn_loc: 0.0425  time: 2.8190  data_time: 0.0964  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:46:00 d2.utils.events]: \u001b[0m eta: 13:57:59  iter: 239  total_loss: 0.2967  loss_cls: 0.1069  loss_box_reg: 0.1247  loss_rpn_cls: 0.01843  loss_rpn_loc: 0.02356  time: 2.8275  data_time: 0.1706  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:46:59 d2.utils.events]: \u001b[0m eta: 14:00:19  iter: 259  total_loss: 0.2511  loss_cls: 0.08591  loss_box_reg: 0.1097  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.03383  time: 2.8373  data_time: 0.1127  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:47:59 d2.utils.events]: \u001b[0m eta: 14:02:10  iter: 279  total_loss: 0.2839  loss_cls: 0.09855  loss_box_reg: 0.1289  loss_rpn_cls: 0.01774  loss_rpn_loc: 0.0358  time: 2.8500  data_time: 0.1065  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:48:59 d2.utils.events]: \u001b[0m eta: 14:04:57  iter: 299  total_loss: 0.2233  loss_cls: 0.08553  loss_box_reg: 0.09985  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.02384  time: 2.8602  data_time: 0.1064  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:49:58 d2.utils.events]: \u001b[0m eta: 14:05:23  iter: 319  total_loss: 0.221  loss_cls: 0.09036  loss_box_reg: 0.09683  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.02438  time: 2.8644  data_time: 0.0867  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:50:58 d2.utils.events]: \u001b[0m eta: 14:05:20  iter: 339  total_loss: 0.2414  loss_cls: 0.08388  loss_box_reg: 0.1173  loss_rpn_cls: 0.01924  loss_rpn_loc: 0.02895  time: 2.8725  data_time: 0.1778  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:51:58 d2.utils.events]: \u001b[0m eta: 14:08:13  iter: 359  total_loss: 0.2745  loss_cls: 0.09123  loss_box_reg: 0.1258  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.02915  time: 2.8806  data_time: 0.1031  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:52:56 d2.utils.events]: \u001b[0m eta: 14:08:16  iter: 379  total_loss: 0.2167  loss_cls: 0.07286  loss_box_reg: 0.106  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.02602  time: 2.8800  data_time: 0.1055  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:53:53 d2.utils.events]: \u001b[0m eta: 14:07:18  iter: 399  total_loss: 0.2257  loss_cls: 0.07234  loss_box_reg: 0.09835  loss_rpn_cls: 0.01786  loss_rpn_loc: 0.02678  time: 2.8799  data_time: 0.0918  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:54:50 d2.utils.events]: \u001b[0m eta: 14:05:20  iter: 419  total_loss: 0.2406  loss_cls: 0.0875  loss_box_reg: 0.1028  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.02105  time: 2.8787  data_time: 0.1087  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:55:47 d2.utils.events]: \u001b[0m eta: 14:02:17  iter: 439  total_loss: 0.2327  loss_cls: 0.08866  loss_box_reg: 0.1057  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.0222  time: 2.8756  data_time: 0.1091  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:56:47 d2.utils.events]: \u001b[0m eta: 14:02:56  iter: 459  total_loss: 0.2297  loss_cls: 0.08313  loss_box_reg: 0.09225  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.03248  time: 2.8827  data_time: 0.1085  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:57:45 d2.utils.events]: \u001b[0m eta: 14:03:27  iter: 479  total_loss: 0.2127  loss_cls: 0.07708  loss_box_reg: 0.09319  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.02559  time: 2.8826  data_time: 0.1165  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:58:44 d2.utils.events]: \u001b[0m eta: 14:03:48  iter: 499  total_loss: 0.2264  loss_cls: 0.07124  loss_box_reg: 0.1021  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.03586  time: 2.8863  data_time: 0.1024  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 19:59:46 d2.utils.events]: \u001b[0m eta: 14:05:35  iter: 519  total_loss: 0.2034  loss_cls: 0.06915  loss_box_reg: 0.09939  loss_rpn_cls: 0.01201  loss_rpn_loc: 0.02182  time: 2.8930  data_time: 0.0767  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:00:46 d2.utils.events]: \u001b[0m eta: 14:05:36  iter: 539  total_loss: 0.1956  loss_cls: 0.05988  loss_box_reg: 0.0793  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.02114  time: 2.8974  data_time: 0.1033  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:01:45 d2.utils.events]: \u001b[0m eta: 14:04:57  iter: 559  total_loss: 0.222  loss_cls: 0.07529  loss_box_reg: 0.1027  loss_rpn_cls: 0.01256  loss_rpn_loc: 0.0245  time: 2.8999  data_time: 0.1119  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:02:44 d2.utils.events]: \u001b[0m eta: 14:05:32  iter: 579  total_loss: 0.2293  loss_cls: 0.07492  loss_box_reg: 0.1096  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.03231  time: 2.9013  data_time: 0.0936  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:03:41 d2.utils.events]: \u001b[0m eta: 14:03:24  iter: 599  total_loss: 0.1784  loss_cls: 0.06037  loss_box_reg: 0.07988  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.02047  time: 2.9002  data_time: 0.1134  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:04:41 d2.utils.events]: \u001b[0m eta: 14:03:35  iter: 619  total_loss: 0.1991  loss_cls: 0.06067  loss_box_reg: 0.08364  loss_rpn_cls: 0.01157  loss_rpn_loc: 0.02408  time: 2.9025  data_time: 0.1000  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:05:38 d2.utils.events]: \u001b[0m eta: 14:01:05  iter: 639  total_loss: 0.1827  loss_cls: 0.06471  loss_box_reg: 0.08722  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.01925  time: 2.9015  data_time: 0.1063  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:06:37 d2.utils.events]: \u001b[0m eta: 13:59:59  iter: 659  total_loss: 0.1692  loss_cls: 0.05357  loss_box_reg: 0.08167  loss_rpn_cls: 0.00997  loss_rpn_loc: 0.01628  time: 2.9021  data_time: 0.1096  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:07:34 d2.utils.events]: \u001b[0m eta: 13:59:01  iter: 679  total_loss: 0.1976  loss_cls: 0.06135  loss_box_reg: 0.0841  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.02026  time: 2.9016  data_time: 0.1012  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:08:34 d2.utils.events]: \u001b[0m eta: 13:58:10  iter: 699  total_loss: 0.2239  loss_cls: 0.06618  loss_box_reg: 0.1003  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.02745  time: 2.9036  data_time: 0.0958  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:09:34 d2.utils.events]: \u001b[0m eta: 13:58:20  iter: 719  total_loss: 0.1699  loss_cls: 0.05793  loss_box_reg: 0.08138  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.02386  time: 2.9069  data_time: 0.1074  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:10:34 d2.utils.events]: \u001b[0m eta: 13:57:46  iter: 739  total_loss: 0.1736  loss_cls: 0.05603  loss_box_reg: 0.08893  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.02054  time: 2.9085  data_time: 0.0982  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:11:33 d2.utils.events]: \u001b[0m eta: 13:56:52  iter: 759  total_loss: 0.1821  loss_cls: 0.05913  loss_box_reg: 0.08613  loss_rpn_cls: 0.0121  loss_rpn_loc: 0.0265  time: 2.9096  data_time: 0.1102  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:12:30 d2.utils.events]: \u001b[0m eta: 13:55:49  iter: 779  total_loss: 0.1674  loss_cls: 0.06446  loss_box_reg: 0.07842  loss_rpn_cls: 0.01112  loss_rpn_loc: 0.01648  time: 2.9090  data_time: 0.1283  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:13:29 d2.utils.events]: \u001b[0m eta: 13:54:27  iter: 799  total_loss: 0.1862  loss_cls: 0.0603  loss_box_reg: 0.09337  loss_rpn_cls: 0.01072  loss_rpn_loc: 0.0205  time: 2.9094  data_time: 0.1056  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:14:29 d2.utils.events]: \u001b[0m eta: 13:53:57  iter: 819  total_loss: 0.1943  loss_cls: 0.05502  loss_box_reg: 0.1031  loss_rpn_cls: 0.009492  loss_rpn_loc: 0.0257  time: 2.9114  data_time: 0.1111  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:15:27 d2.utils.events]: \u001b[0m eta: 13:54:00  iter: 839  total_loss: 0.1548  loss_cls: 0.04827  loss_box_reg: 0.07996  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.02253  time: 2.9113  data_time: 0.1063  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:16:27 d2.utils.events]: \u001b[0m eta: 13:53:36  iter: 859  total_loss: 0.1567  loss_cls: 0.04823  loss_box_reg: 0.07523  loss_rpn_cls: 0.007942  loss_rpn_loc: 0.01719  time: 2.9131  data_time: 0.0974  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:17:28 d2.utils.events]: \u001b[0m eta: 13:54:43  iter: 879  total_loss: 0.1587  loss_cls: 0.04072  loss_box_reg: 0.06977  loss_rpn_cls: 0.0119  loss_rpn_loc: 0.01992  time: 2.9163  data_time: 0.0959  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:18:28 d2.utils.events]: \u001b[0m eta: 13:54:09  iter: 899  total_loss: 0.1359  loss_cls: 0.04465  loss_box_reg: 0.06389  loss_rpn_cls: 0.01032  loss_rpn_loc: 0.02121  time: 2.9188  data_time: 0.0976  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:19:26 d2.utils.events]: \u001b[0m eta: 13:52:56  iter: 919  total_loss: 0.165  loss_cls: 0.05048  loss_box_reg: 0.0821  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.02464  time: 2.9182  data_time: 0.0948  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:20:27 d2.utils.events]: \u001b[0m eta: 13:52:30  iter: 939  total_loss: 0.1464  loss_cls: 0.04155  loss_box_reg: 0.06416  loss_rpn_cls: 0.008845  loss_rpn_loc: 0.02387  time: 2.9210  data_time: 0.1220  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:21:25 d2.utils.events]: \u001b[0m eta: 13:51:21  iter: 959  total_loss: 0.1575  loss_cls: 0.04759  loss_box_reg: 0.08389  loss_rpn_cls: 0.007548  loss_rpn_loc: 0.01626  time: 2.9204  data_time: 0.1008  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:22:24 d2.utils.events]: \u001b[0m eta: 13:50:29  iter: 979  total_loss: 0.1574  loss_cls: 0.04671  loss_box_reg: 0.089  loss_rpn_cls: 0.009118  loss_rpn_loc: 0.02054  time: 2.9214  data_time: 0.1295  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:23:23 d2.utils.events]: \u001b[0m eta: 13:49:33  iter: 999  total_loss: 0.1603  loss_cls: 0.04348  loss_box_reg: 0.092  loss_rpn_cls: 0.009257  loss_rpn_loc: 0.01675  time: 2.9212  data_time: 0.1105  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:24:24 d2.utils.events]: \u001b[0m eta: 13:50:40  iter: 1019  total_loss: 0.1357  loss_cls: 0.036  loss_box_reg: 0.05735  loss_rpn_cls: 0.00815  loss_rpn_loc: 0.02447  time: 2.9239  data_time: 0.1020  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:25:24 d2.utils.events]: \u001b[0m eta: 13:51:39  iter: 1039  total_loss: 0.1447  loss_cls: 0.04143  loss_box_reg: 0.07444  loss_rpn_cls: 0.00665  loss_rpn_loc: 0.02224  time: 2.9257  data_time: 0.1105  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:26:21 d2.utils.events]: \u001b[0m eta: 13:51:14  iter: 1059  total_loss: 0.1639  loss_cls: 0.04491  loss_box_reg: 0.07646  loss_rpn_cls: 0.01106  loss_rpn_loc: 0.02653  time: 2.9244  data_time: 0.0951  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:27:20 d2.utils.events]: \u001b[0m eta: 13:51:12  iter: 1079  total_loss: 0.1594  loss_cls: 0.04504  loss_box_reg: 0.08344  loss_rpn_cls: 0.009863  loss_rpn_loc: 0.021  time: 2.9246  data_time: 0.1068  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:28:19 d2.utils.events]: \u001b[0m eta: 13:49:31  iter: 1099  total_loss: 0.1439  loss_cls: 0.03977  loss_box_reg: 0.07129  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.02428  time: 2.9254  data_time: 0.1040  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:29:18 d2.utils.events]: \u001b[0m eta: 13:48:42  iter: 1119  total_loss: 0.1265  loss_cls: 0.03358  loss_box_reg: 0.06682  loss_rpn_cls: 0.007873  loss_rpn_loc: 0.01411  time: 2.9257  data_time: 0.0857  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:30:16 d2.utils.events]: \u001b[0m eta: 13:48:01  iter: 1139  total_loss: 0.1635  loss_cls: 0.04847  loss_box_reg: 0.1014  loss_rpn_cls: 0.008296  loss_rpn_loc: 0.01806  time: 2.9250  data_time: 0.0935  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:31:15 d2.utils.events]: \u001b[0m eta: 13:46:20  iter: 1159  total_loss: 0.1298  loss_cls: 0.03513  loss_box_reg: 0.062  loss_rpn_cls: 0.01108  loss_rpn_loc: 0.02419  time: 2.9254  data_time: 0.1076  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:32:11 d2.utils.events]: \u001b[0m eta: 13:45:00  iter: 1179  total_loss: 0.1358  loss_cls: 0.04035  loss_box_reg: 0.06997  loss_rpn_cls: 0.007953  loss_rpn_loc: 0.01568  time: 2.9235  data_time: 0.0919  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:33:10 d2.utils.events]: \u001b[0m eta: 13:44:14  iter: 1199  total_loss: 0.1471  loss_cls: 0.04249  loss_box_reg: 0.08218  loss_rpn_cls: 0.009948  loss_rpn_loc: 0.0177  time: 2.9239  data_time: 0.0969  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:34:10 d2.utils.events]: \u001b[0m eta: 13:44:25  iter: 1219  total_loss: 0.1666  loss_cls: 0.03601  loss_box_reg: 0.08206  loss_rpn_cls: 0.0076  loss_rpn_loc: 0.02044  time: 2.9253  data_time: 0.1598  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:35:09 d2.utils.events]: \u001b[0m eta: 13:43:06  iter: 1239  total_loss: 0.1451  loss_cls: 0.04125  loss_box_reg: 0.0774  loss_rpn_cls: 0.006899  loss_rpn_loc: 0.0181  time: 2.9251  data_time: 0.0835  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:36:10 d2.utils.events]: \u001b[0m eta: 13:42:44  iter: 1259  total_loss: 0.1524  loss_cls: 0.04341  loss_box_reg: 0.08026  loss_rpn_cls: 0.006486  loss_rpn_loc: 0.01659  time: 2.9271  data_time: 0.1096  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:37:07 d2.utils.events]: \u001b[0m eta: 13:40:58  iter: 1279  total_loss: 0.124  loss_cls: 0.03382  loss_box_reg: 0.05896  loss_rpn_cls: 0.00573  loss_rpn_loc: 0.01758  time: 2.9263  data_time: 0.1019  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:38:08 d2.utils.events]: \u001b[0m eta: 13:40:00  iter: 1299  total_loss: 0.1727  loss_cls: 0.04805  loss_box_reg: 0.0886  loss_rpn_cls: 0.008628  loss_rpn_loc: 0.01945  time: 2.9279  data_time: 0.1024  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:39:07 d2.utils.events]: \u001b[0m eta: 13:39:10  iter: 1319  total_loss: 0.1422  loss_cls: 0.04415  loss_box_reg: 0.07479  loss_rpn_cls: 0.007699  loss_rpn_loc: 0.01745  time: 2.9283  data_time: 0.1118  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:40:09 d2.utils.events]: \u001b[0m eta: 13:39:02  iter: 1339  total_loss: 0.1129  loss_cls: 0.03117  loss_box_reg: 0.05913  loss_rpn_cls: 0.006094  loss_rpn_loc: 0.01684  time: 2.9313  data_time: 0.1003  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:41:08 d2.utils.events]: \u001b[0m eta: 13:36:55  iter: 1359  total_loss: 0.1363  loss_cls: 0.03228  loss_box_reg: 0.05862  loss_rpn_cls: 0.008587  loss_rpn_loc: 0.02156  time: 2.9313  data_time: 0.1022  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:42:06 d2.utils.events]: \u001b[0m eta: 13:35:52  iter: 1379  total_loss: 0.1409  loss_cls: 0.04024  loss_box_reg: 0.06294  loss_rpn_cls: 0.006349  loss_rpn_loc: 0.02029  time: 2.9308  data_time: 0.0961  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:43:05 d2.utils.events]: \u001b[0m eta: 13:35:29  iter: 1399  total_loss: 0.1263  loss_cls: 0.03787  loss_box_reg: 0.06978  loss_rpn_cls: 0.007535  loss_rpn_loc: 0.01827  time: 2.9314  data_time: 0.1013  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:44:05 d2.utils.events]: \u001b[0m eta: 13:35:42  iter: 1419  total_loss: 0.1427  loss_cls: 0.03938  loss_box_reg: 0.08143  loss_rpn_cls: 0.006647  loss_rpn_loc: 0.01689  time: 2.9323  data_time: 0.1088  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:45:03 d2.utils.events]: \u001b[0m eta: 13:35:36  iter: 1439  total_loss: 0.1194  loss_cls: 0.03193  loss_box_reg: 0.05584  loss_rpn_cls: 0.006172  loss_rpn_loc: 0.01746  time: 2.9318  data_time: 0.0735  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:46:00 d2.utils.events]: \u001b[0m eta: 13:33:23  iter: 1459  total_loss: 0.1466  loss_cls: 0.04368  loss_box_reg: 0.06952  loss_rpn_cls: 0.00998  loss_rpn_loc: 0.019  time: 2.9307  data_time: 0.1071  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:47:01 d2.utils.events]: \u001b[0m eta: 13:32:45  iter: 1479  total_loss: 0.1776  loss_cls: 0.05913  loss_box_reg: 0.08144  loss_rpn_cls: 0.009732  loss_rpn_loc: 0.02087  time: 2.9321  data_time: 0.1104  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:47:58 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /content/gdrive/MyDrive/fsdet-v/model_0001499.pth\n",
            "\u001b[32m[07/28 20:48:01 d2.utils.events]: \u001b[0m eta: 13:30:14  iter: 1499  total_loss: 0.1389  loss_cls: 0.03758  loss_box_reg: 0.06465  loss_rpn_cls: 0.007277  loss_rpn_loc: 0.01964  time: 2.9310  data_time: 0.1104  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:49:03 d2.utils.events]: \u001b[0m eta: 13:29:41  iter: 1519  total_loss: 0.1726  loss_cls: 0.04147  loss_box_reg: 0.08827  loss_rpn_cls: 0.007892  loss_rpn_loc: 0.02497  time: 2.9332  data_time: 0.1124  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:50:03 d2.utils.events]: \u001b[0m eta: 13:29:04  iter: 1539  total_loss: 0.1313  loss_cls: 0.03613  loss_box_reg: 0.06394  loss_rpn_cls: 0.006132  loss_rpn_loc: 0.01796  time: 2.9342  data_time: 0.1238  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:51:00 d2.utils.events]: \u001b[0m eta: 13:27:21  iter: 1559  total_loss: 0.1493  loss_cls: 0.04315  loss_box_reg: 0.07433  loss_rpn_cls: 0.006484  loss_rpn_loc: 0.0157  time: 2.9331  data_time: 0.1074  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:51:59 d2.utils.events]: \u001b[0m eta: 13:25:46  iter: 1579  total_loss: 0.1085  loss_cls: 0.03198  loss_box_reg: 0.05853  loss_rpn_cls: 0.005601  loss_rpn_loc: 0.0147  time: 2.9335  data_time: 0.0894  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:52:58 d2.utils.events]: \u001b[0m eta: 13:25:02  iter: 1599  total_loss: 0.1469  loss_cls: 0.04218  loss_box_reg: 0.07869  loss_rpn_cls: 0.00657  loss_rpn_loc: 0.0182  time: 2.9333  data_time: 0.0981  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:53:56 d2.utils.events]: \u001b[0m eta: 13:23:57  iter: 1619  total_loss: 0.1195  loss_cls: 0.03051  loss_box_reg: 0.06678  loss_rpn_cls: 0.006345  loss_rpn_loc: 0.01668  time: 2.9334  data_time: 0.1024  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:54:54 d2.utils.events]: \u001b[0m eta: 13:23:25  iter: 1639  total_loss: 0.1363  loss_cls: 0.03477  loss_box_reg: 0.06992  loss_rpn_cls: 0.005202  loss_rpn_loc: 0.01401  time: 2.9329  data_time: 0.1061  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:55:52 d2.utils.events]: \u001b[0m eta: 13:22:26  iter: 1659  total_loss: 0.126  loss_cls: 0.03261  loss_box_reg: 0.05978  loss_rpn_cls: 0.005657  loss_rpn_loc: 0.01771  time: 2.9325  data_time: 0.0938  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:56:50 d2.utils.events]: \u001b[0m eta: 13:21:27  iter: 1679  total_loss: 0.1297  loss_cls: 0.03399  loss_box_reg: 0.06996  loss_rpn_cls: 0.005802  loss_rpn_loc: 0.01505  time: 2.9316  data_time: 0.0999  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:57:46 d2.utils.events]: \u001b[0m eta: 13:20:07  iter: 1699  total_loss: 0.107  loss_cls: 0.02882  loss_box_reg: 0.05932  loss_rpn_cls: 0.006464  loss_rpn_loc: 0.01767  time: 2.9301  data_time: 0.1082  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:58:42 d2.utils.events]: \u001b[0m eta: 13:18:18  iter: 1719  total_loss: 0.133  loss_cls: 0.03545  loss_box_reg: 0.07249  loss_rpn_cls: 0.006246  loss_rpn_loc: 0.01897  time: 2.9287  data_time: 0.0935  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 20:59:40 d2.utils.events]: \u001b[0m eta: 13:16:24  iter: 1739  total_loss: 0.1244  loss_cls: 0.03331  loss_box_reg: 0.06606  loss_rpn_cls: 0.004762  loss_rpn_loc: 0.01636  time: 2.9285  data_time: 0.0735  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:00:40 d2.utils.events]: \u001b[0m eta: 13:15:17  iter: 1759  total_loss: 0.1274  loss_cls: 0.03347  loss_box_reg: 0.06713  loss_rpn_cls: 0.004774  loss_rpn_loc: 0.01851  time: 2.9292  data_time: 0.1291  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:01:41 d2.utils.events]: \u001b[0m eta: 13:15:29  iter: 1779  total_loss: 0.1083  loss_cls: 0.02697  loss_box_reg: 0.05405  loss_rpn_cls: 0.004194  loss_rpn_loc: 0.01356  time: 2.9305  data_time: 0.1067  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:02:37 d2.utils.events]: \u001b[0m eta: 13:14:30  iter: 1799  total_loss: 0.1142  loss_cls: 0.03199  loss_box_reg: 0.06307  loss_rpn_cls: 0.005757  loss_rpn_loc: 0.01406  time: 2.9294  data_time: 0.1066  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:03:37 d2.utils.events]: \u001b[0m eta: 13:13:31  iter: 1819  total_loss: 0.1105  loss_cls: 0.02961  loss_box_reg: 0.05401  loss_rpn_cls: 0.005541  loss_rpn_loc: 0.01905  time: 2.9300  data_time: 0.1120  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:04:37 d2.utils.events]: \u001b[0m eta: 13:12:40  iter: 1839  total_loss: 0.1132  loss_cls: 0.03098  loss_box_reg: 0.05985  loss_rpn_cls: 0.005049  loss_rpn_loc: 0.0186  time: 2.9305  data_time: 0.0923  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:05:38 d2.utils.events]: \u001b[0m eta: 13:11:41  iter: 1859  total_loss: 0.1178  loss_cls: 0.02974  loss_box_reg: 0.05623  loss_rpn_cls: 0.005168  loss_rpn_loc: 0.02148  time: 2.9318  data_time: 0.1077  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:06:36 d2.utils.events]: \u001b[0m eta: 13:09:24  iter: 1879  total_loss: 0.1075  loss_cls: 0.02947  loss_box_reg: 0.05667  loss_rpn_cls: 0.004476  loss_rpn_loc: 0.01247  time: 2.9316  data_time: 0.1060  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:07:35 d2.utils.events]: \u001b[0m eta: 13:07:50  iter: 1899  total_loss: 0.1112  loss_cls: 0.02576  loss_box_reg: 0.06143  loss_rpn_cls: 0.00614  loss_rpn_loc: 0.01803  time: 2.9319  data_time: 0.0987  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:08:36 d2.utils.events]: \u001b[0m eta: 13:07:09  iter: 1919  total_loss: 0.1071  loss_cls: 0.03023  loss_box_reg: 0.06528  loss_rpn_cls: 0.00437  loss_rpn_loc: 0.01297  time: 2.9330  data_time: 0.1005  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:09:34 d2.utils.events]: \u001b[0m eta: 13:05:06  iter: 1939  total_loss: 0.09585  loss_cls: 0.02555  loss_box_reg: 0.05393  loss_rpn_cls: 0.003984  loss_rpn_loc: 0.01435  time: 2.9327  data_time: 0.0937  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:10:33 d2.utils.events]: \u001b[0m eta: 13:04:24  iter: 1959  total_loss: 0.1206  loss_cls: 0.03196  loss_box_reg: 0.06603  loss_rpn_cls: 0.006441  loss_rpn_loc: 0.0165  time: 2.9329  data_time: 0.0948  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:11:34 d2.utils.events]: \u001b[0m eta: 13:03:25  iter: 1979  total_loss: 0.09653  loss_cls: 0.02611  loss_box_reg: 0.04861  loss_rpn_cls: 0.004935  loss_rpn_loc: 0.01575  time: 2.9340  data_time: 0.0999  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:12:32 d2.utils.events]: \u001b[0m eta: 13:02:10  iter: 1999  total_loss: 0.117  loss_cls: 0.02975  loss_box_reg: 0.06708  loss_rpn_cls: 0.00448  loss_rpn_loc: 0.0151  time: 2.9336  data_time: 0.1130  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:13:28 d2.utils.events]: \u001b[0m eta: 13:00:33  iter: 2019  total_loss: 0.1068  loss_cls: 0.02928  loss_box_reg: 0.05616  loss_rpn_cls: 0.00479  loss_rpn_loc: 0.02514  time: 2.9324  data_time: 0.0996  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:14:26 d2.utils.events]: \u001b[0m eta: 12:58:58  iter: 2039  total_loss: 0.1152  loss_cls: 0.03195  loss_box_reg: 0.06422  loss_rpn_cls: 0.004328  loss_rpn_loc: 0.0144  time: 2.9320  data_time: 0.1030  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:15:25 d2.utils.events]: \u001b[0m eta: 12:58:15  iter: 2059  total_loss: 0.1194  loss_cls: 0.02704  loss_box_reg: 0.06248  loss_rpn_cls: 0.005477  loss_rpn_loc: 0.01766  time: 2.9321  data_time: 0.1313  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:16:23 d2.utils.events]: \u001b[0m eta: 12:56:57  iter: 2079  total_loss: 0.1077  loss_cls: 0.02718  loss_box_reg: 0.05796  loss_rpn_cls: 0.004681  loss_rpn_loc: 0.01222  time: 2.9320  data_time: 0.0985  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:17:20 d2.utils.events]: \u001b[0m eta: 12:55:46  iter: 2099  total_loss: 0.1293  loss_cls: 0.03543  loss_box_reg: 0.07241  loss_rpn_cls: 0.003703  loss_rpn_loc: 0.01482  time: 2.9314  data_time: 0.1119  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:18:18 d2.utils.events]: \u001b[0m eta: 12:54:35  iter: 2119  total_loss: 0.1407  loss_cls: 0.03721  loss_box_reg: 0.07215  loss_rpn_cls: 0.004452  loss_rpn_loc: 0.01567  time: 2.9309  data_time: 0.0896  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:19:17 d2.utils.events]: \u001b[0m eta: 12:53:36  iter: 2139  total_loss: 0.1253  loss_cls: 0.03284  loss_box_reg: 0.07028  loss_rpn_cls: 0.005298  loss_rpn_loc: 0.01879  time: 2.9309  data_time: 0.1096  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:20:15 d2.utils.events]: \u001b[0m eta: 12:52:56  iter: 2159  total_loss: 0.1143  loss_cls: 0.02893  loss_box_reg: 0.05798  loss_rpn_cls: 0.005464  loss_rpn_loc: 0.01574  time: 2.9308  data_time: 0.1176  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:21:15 d2.utils.events]: \u001b[0m eta: 12:52:50  iter: 2179  total_loss: 0.1173  loss_cls: 0.02985  loss_box_reg: 0.06785  loss_rpn_cls: 0.00406  loss_rpn_loc: 0.0189  time: 2.9314  data_time: 0.1139  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:22:15 d2.utils.events]: \u001b[0m eta: 12:51:52  iter: 2199  total_loss: 0.09247  loss_cls: 0.02179  loss_box_reg: 0.05013  loss_rpn_cls: 0.004937  loss_rpn_loc: 0.0129  time: 2.9318  data_time: 0.0924  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:23:16 d2.utils.events]: \u001b[0m eta: 12:51:07  iter: 2219  total_loss: 0.1189  loss_cls: 0.02821  loss_box_reg: 0.06142  loss_rpn_cls: 0.003901  loss_rpn_loc: 0.01639  time: 2.9329  data_time: 0.0939  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:24:13 d2.utils.events]: \u001b[0m eta: 12:50:48  iter: 2239  total_loss: 0.1044  loss_cls: 0.02459  loss_box_reg: 0.05922  loss_rpn_cls: 0.004167  loss_rpn_loc: 0.01691  time: 2.9323  data_time: 0.1070  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:25:13 d2.utils.events]: \u001b[0m eta: 12:49:08  iter: 2259  total_loss: 0.1054  loss_cls: 0.02609  loss_box_reg: 0.05819  loss_rpn_cls: 0.004133  loss_rpn_loc: 0.01341  time: 2.9330  data_time: 0.1101  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:26:15 d2.utils.events]: \u001b[0m eta: 12:50:08  iter: 2279  total_loss: 0.09885  loss_cls: 0.02194  loss_box_reg: 0.05661  loss_rpn_cls: 0.002983  loss_rpn_loc: 0.01307  time: 2.9343  data_time: 0.1012  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:27:17 d2.utils.events]: \u001b[0m eta: 12:49:09  iter: 2299  total_loss: 0.09333  loss_cls: 0.02169  loss_box_reg: 0.04968  loss_rpn_cls: 0.003944  loss_rpn_loc: 0.01959  time: 2.9358  data_time: 0.1034  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:28:19 d2.utils.events]: \u001b[0m eta: 12:48:21  iter: 2319  total_loss: 0.1116  loss_cls: 0.02693  loss_box_reg: 0.05571  loss_rpn_cls: 0.004293  loss_rpn_loc: 0.02246  time: 2.9371  data_time: 0.1078  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:29:21 d2.utils.events]: \u001b[0m eta: 12:47:16  iter: 2339  total_loss: 0.1125  loss_cls: 0.02901  loss_box_reg: 0.0578  loss_rpn_cls: 0.002789  loss_rpn_loc: 0.01637  time: 2.9386  data_time: 0.1102  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:30:21 d2.utils.events]: \u001b[0m eta: 12:47:34  iter: 2359  total_loss: 0.07558  loss_cls: 0.02072  loss_box_reg: 0.04253  loss_rpn_cls: 0.003818  loss_rpn_loc: 0.01228  time: 2.9392  data_time: 0.0911  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:31:21 d2.utils.events]: \u001b[0m eta: 12:46:51  iter: 2379  total_loss: 0.09836  loss_cls: 0.02318  loss_box_reg: 0.0536  loss_rpn_cls: 0.004876  loss_rpn_loc: 0.0176  time: 2.9397  data_time: 0.1292  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:32:22 d2.utils.events]: \u001b[0m eta: 12:45:47  iter: 2399  total_loss: 0.1123  loss_cls: 0.02875  loss_box_reg: 0.06381  loss_rpn_cls: 0.004464  loss_rpn_loc: 0.01601  time: 2.9405  data_time: 0.0973  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:33:22 d2.utils.events]: \u001b[0m eta: 12:44:43  iter: 2419  total_loss: 0.1108  loss_cls: 0.02968  loss_box_reg: 0.06482  loss_rpn_cls: 0.004631  loss_rpn_loc: 0.01814  time: 2.9409  data_time: 0.1148  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:34:24 d2.utils.events]: \u001b[0m eta: 12:44:29  iter: 2439  total_loss: 0.1154  loss_cls: 0.03292  loss_box_reg: 0.06029  loss_rpn_cls: 0.004152  loss_rpn_loc: 0.01863  time: 2.9422  data_time: 0.1132  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:35:24 d2.utils.events]: \u001b[0m eta: 12:44:57  iter: 2459  total_loss: 0.1318  loss_cls: 0.03562  loss_box_reg: 0.07703  loss_rpn_cls: 0.004073  loss_rpn_loc: 0.01625  time: 2.9428  data_time: 0.1083  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:36:24 d2.utils.events]: \u001b[0m eta: 12:44:21  iter: 2479  total_loss: 0.08113  loss_cls: 0.02305  loss_box_reg: 0.04177  loss_rpn_cls: 0.004022  loss_rpn_loc: 0.01584  time: 2.9433  data_time: 0.0704  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:37:25 d2.utils.events]: \u001b[0m eta: 12:44:20  iter: 2499  total_loss: 0.101  loss_cls: 0.02635  loss_box_reg: 0.05256  loss_rpn_cls: 0.003838  loss_rpn_loc: 0.01576  time: 2.9441  data_time: 0.0758  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:38:25 d2.utils.events]: \u001b[0m eta: 12:43:06  iter: 2519  total_loss: 0.09665  loss_cls: 0.02406  loss_box_reg: 0.05105  loss_rpn_cls: 0.00383  loss_rpn_loc: 0.01441  time: 2.9445  data_time: 0.1079  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:39:27 d2.utils.events]: \u001b[0m eta: 12:42:12  iter: 2539  total_loss: 0.1039  loss_cls: 0.02598  loss_box_reg: 0.05069  loss_rpn_cls: 0.003584  loss_rpn_loc: 0.01528  time: 2.9459  data_time: 0.1058  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:40:29 d2.utils.events]: \u001b[0m eta: 12:41:53  iter: 2559  total_loss: 0.0993  loss_cls: 0.02593  loss_box_reg: 0.05676  loss_rpn_cls: 0.004099  loss_rpn_loc: 0.01458  time: 2.9470  data_time: 0.1075  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:41:29 d2.utils.events]: \u001b[0m eta: 12:41:14  iter: 2579  total_loss: 0.09149  loss_cls: 0.02134  loss_box_reg: 0.04816  loss_rpn_cls: 0.003502  loss_rpn_loc: 0.01467  time: 2.9474  data_time: 0.1482  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:42:30 d2.utils.events]: \u001b[0m eta: 12:40:50  iter: 2599  total_loss: 0.09962  loss_cls: 0.02099  loss_box_reg: 0.04694  loss_rpn_cls: 0.00361  loss_rpn_loc: 0.0158  time: 2.9481  data_time: 0.1004  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:43:31 d2.utils.events]: \u001b[0m eta: 12:40:11  iter: 2619  total_loss: 0.1243  loss_cls: 0.02753  loss_box_reg: 0.06582  loss_rpn_cls: 0.004551  loss_rpn_loc: 0.01823  time: 2.9491  data_time: 0.0904  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:44:32 d2.utils.events]: \u001b[0m eta: 12:39:42  iter: 2639  total_loss: 0.0914  loss_cls: 0.02101  loss_box_reg: 0.04918  loss_rpn_cls: 0.004142  loss_rpn_loc: 0.01013  time: 2.9497  data_time: 0.0905  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:45:33 d2.utils.events]: \u001b[0m eta: 12:39:11  iter: 2659  total_loss: 0.09016  loss_cls: 0.02062  loss_box_reg: 0.04869  loss_rpn_cls: 0.003981  loss_rpn_loc: 0.0142  time: 2.9503  data_time: 0.1108  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:46:34 d2.utils.events]: \u001b[0m eta: 12:39:18  iter: 2679  total_loss: 0.0981  loss_cls: 0.02321  loss_box_reg: 0.05598  loss_rpn_cls: 0.003013  loss_rpn_loc: 0.01371  time: 2.9511  data_time: 0.0975  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:47:33 d2.utils.events]: \u001b[0m eta: 12:38:21  iter: 2699  total_loss: 0.1105  loss_cls: 0.03014  loss_box_reg: 0.05783  loss_rpn_cls: 0.004807  loss_rpn_loc: 0.01488  time: 2.9512  data_time: 0.0917  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:48:35 d2.utils.events]: \u001b[0m eta: 12:39:04  iter: 2719  total_loss: 0.07782  loss_cls: 0.01979  loss_box_reg: 0.04075  loss_rpn_cls: 0.004814  loss_rpn_loc: 0.01685  time: 2.9523  data_time: 0.1026  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:49:37 d2.utils.events]: \u001b[0m eta: 12:39:32  iter: 2739  total_loss: 0.09261  loss_cls: 0.02075  loss_box_reg: 0.05409  loss_rpn_cls: 0.003369  loss_rpn_loc: 0.01377  time: 2.9533  data_time: 0.1007  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:50:38 d2.utils.events]: \u001b[0m eta: 12:38:50  iter: 2759  total_loss: 0.1085  loss_cls: 0.02627  loss_box_reg: 0.05946  loss_rpn_cls: 0.003353  loss_rpn_loc: 0.01437  time: 2.9540  data_time: 0.1076  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:51:41 d2.utils.events]: \u001b[0m eta: 12:38:07  iter: 2779  total_loss: 0.09523  loss_cls: 0.02118  loss_box_reg: 0.05962  loss_rpn_cls: 0.002759  loss_rpn_loc: 0.01419  time: 2.9555  data_time: 0.1138  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:52:44 d2.utils.events]: \u001b[0m eta: 12:37:35  iter: 2799  total_loss: 0.07565  loss_cls: 0.01733  loss_box_reg: 0.04573  loss_rpn_cls: 0.002535  loss_rpn_loc: 0.01509  time: 2.9568  data_time: 0.1545  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:53:44 d2.utils.events]: \u001b[0m eta: 12:36:27  iter: 2819  total_loss: 0.09275  loss_cls: 0.02083  loss_box_reg: 0.05443  loss_rpn_cls: 0.003266  loss_rpn_loc: 0.01495  time: 2.9571  data_time: 0.0858  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:54:45 d2.utils.events]: \u001b[0m eta: 12:35:43  iter: 2839  total_loss: 0.08833  loss_cls: 0.02168  loss_box_reg: 0.04943  loss_rpn_cls: 0.002791  loss_rpn_loc: 0.01449  time: 2.9577  data_time: 0.1044  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:55:44 d2.utils.events]: \u001b[0m eta: 12:34:43  iter: 2859  total_loss: 0.08667  loss_cls: 0.0229  loss_box_reg: 0.0464  loss_rpn_cls: 0.004046  loss_rpn_loc: 0.01474  time: 2.9577  data_time: 0.0844  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:56:46 d2.utils.events]: \u001b[0m eta: 12:34:07  iter: 2879  total_loss: 0.08416  loss_cls: 0.02243  loss_box_reg: 0.045  loss_rpn_cls: 0.003214  loss_rpn_loc: 0.01376  time: 2.9586  data_time: 0.0919  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:57:45 d2.utils.events]: \u001b[0m eta: 12:33:07  iter: 2899  total_loss: 0.08998  loss_cls: 0.02139  loss_box_reg: 0.05287  loss_rpn_cls: 0.003067  loss_rpn_loc: 0.01485  time: 2.9588  data_time: 0.1053  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:58:46 d2.utils.events]: \u001b[0m eta: 12:31:54  iter: 2919  total_loss: 0.08517  loss_cls: 0.01997  loss_box_reg: 0.04827  loss_rpn_cls: 0.003443  loss_rpn_loc: 0.01316  time: 2.9593  data_time: 0.0820  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 21:59:50 d2.utils.events]: \u001b[0m eta: 12:32:38  iter: 2939  total_loss: 0.08986  loss_cls: 0.02025  loss_box_reg: 0.05186  loss_rpn_cls: 0.003466  loss_rpn_loc: 0.01714  time: 2.9608  data_time: 0.1114  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:00:51 d2.utils.events]: \u001b[0m eta: 12:31:42  iter: 2959  total_loss: 0.1006  loss_cls: 0.02686  loss_box_reg: 0.0566  loss_rpn_cls: 0.003644  loss_rpn_loc: 0.01568  time: 2.9615  data_time: 0.0942  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:01:53 d2.utils.events]: \u001b[0m eta: 12:31:01  iter: 2979  total_loss: 0.07336  loss_cls: 0.0164  loss_box_reg: 0.041  loss_rpn_cls: 0.004211  loss_rpn_loc: 0.01863  time: 2.9625  data_time: 0.0987  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:02:53 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /content/gdrive/MyDrive/fsdet-v/model_0002999.pth\n",
            "\u001b[32m[07/28 22:02:56 d2.utils.events]: \u001b[0m eta: 12:30:38  iter: 2999  total_loss: 0.07208  loss_cls: 0.01675  loss_box_reg: 0.03493  loss_rpn_cls: 0.002465  loss_rpn_loc: 0.0123  time: 2.9628  data_time: 0.1066  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:03:55 d2.utils.events]: \u001b[0m eta: 12:30:40  iter: 3019  total_loss: 0.06906  loss_cls: 0.01558  loss_box_reg: 0.03396  loss_rpn_cls: 0.002468  loss_rpn_loc: 0.01044  time: 2.9627  data_time: 0.1143  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:04:55 d2.utils.events]: \u001b[0m eta: 12:30:31  iter: 3039  total_loss: 0.09758  loss_cls: 0.02178  loss_box_reg: 0.05484  loss_rpn_cls: 0.002773  loss_rpn_loc: 0.01428  time: 2.9629  data_time: 0.1122  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:05:54 d2.utils.events]: \u001b[0m eta: 12:30:04  iter: 3059  total_loss: 0.06939  loss_cls: 0.01538  loss_box_reg: 0.03763  loss_rpn_cls: 0.0029  loss_rpn_loc: 0.01198  time: 2.9629  data_time: 0.1736  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:06:56 d2.utils.events]: \u001b[0m eta: 12:29:53  iter: 3079  total_loss: 0.08127  loss_cls: 0.02195  loss_box_reg: 0.04539  loss_rpn_cls: 0.002158  loss_rpn_loc: 0.012  time: 2.9638  data_time: 0.0928  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:07:58 d2.utils.events]: \u001b[0m eta: 12:30:03  iter: 3099  total_loss: 0.091  loss_cls: 0.02132  loss_box_reg: 0.04617  loss_rpn_cls: 0.002906  loss_rpn_loc: 0.01686  time: 2.9648  data_time: 0.0932  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:08:59 d2.utils.events]: \u001b[0m eta: 12:29:23  iter: 3119  total_loss: 0.06174  loss_cls: 0.01286  loss_box_reg: 0.03189  loss_rpn_cls: 0.00321  loss_rpn_loc: 0.01575  time: 2.9653  data_time: 0.1116  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:09:59 d2.utils.events]: \u001b[0m eta: 12:28:29  iter: 3139  total_loss: 0.09077  loss_cls: 0.02133  loss_box_reg: 0.04747  loss_rpn_cls: 0.003992  loss_rpn_loc: 0.0174  time: 2.9654  data_time: 0.1155  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:11:01 d2.utils.events]: \u001b[0m eta: 12:27:51  iter: 3159  total_loss: 0.09176  loss_cls: 0.02127  loss_box_reg: 0.05139  loss_rpn_cls: 0.00358  loss_rpn_loc: 0.01186  time: 2.9663  data_time: 0.0821  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:12:03 d2.utils.events]: \u001b[0m eta: 12:26:51  iter: 3179  total_loss: 0.1005  loss_cls: 0.02373  loss_box_reg: 0.05277  loss_rpn_cls: 0.003923  loss_rpn_loc: 0.0169  time: 2.9671  data_time: 0.0982  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:13:08 d2.utils.events]: \u001b[0m eta: 12:27:42  iter: 3199  total_loss: 0.09575  loss_cls: 0.0223  loss_box_reg: 0.04828  loss_rpn_cls: 0.003177  loss_rpn_loc: 0.01627  time: 2.9688  data_time: 0.1068  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:14:11 d2.utils.events]: \u001b[0m eta: 12:27:16  iter: 3219  total_loss: 0.08162  loss_cls: 0.02144  loss_box_reg: 0.04503  loss_rpn_cls: 0.0034  loss_rpn_loc: 0.01444  time: 2.9700  data_time: 0.0996  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:15:15 d2.utils.events]: \u001b[0m eta: 12:26:42  iter: 3239  total_loss: 0.1138  loss_cls: 0.02533  loss_box_reg: 0.06009  loss_rpn_cls: 0.004533  loss_rpn_loc: 0.01702  time: 2.9714  data_time: 0.1196  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:16:18 d2.utils.events]: \u001b[0m eta: 12:26:05  iter: 3259  total_loss: 0.0896  loss_cls: 0.01951  loss_box_reg: 0.0519  loss_rpn_cls: 0.002332  loss_rpn_loc: 0.01324  time: 2.9725  data_time: 0.0807  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:17:16 d2.utils.events]: \u001b[0m eta: 12:24:44  iter: 3279  total_loss: 0.0692  loss_cls: 0.01966  loss_box_reg: 0.04059  loss_rpn_cls: 0.003048  loss_rpn_loc: 0.01199  time: 2.9722  data_time: 0.1105  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:18:19 d2.utils.events]: \u001b[0m eta: 12:23:54  iter: 3299  total_loss: 0.08021  loss_cls: 0.0185  loss_box_reg: 0.04714  loss_rpn_cls: 0.003263  loss_rpn_loc: 0.01617  time: 2.9733  data_time: 0.0863  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:19:20 d2.utils.events]: \u001b[0m eta: 12:22:46  iter: 3319  total_loss: 0.09201  loss_cls: 0.02304  loss_box_reg: 0.05226  loss_rpn_cls: 0.003434  loss_rpn_loc: 0.02087  time: 2.9737  data_time: 0.0942  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:20:21 d2.utils.events]: \u001b[0m eta: 12:21:38  iter: 3339  total_loss: 0.09575  loss_cls: 0.02244  loss_box_reg: 0.05327  loss_rpn_cls: 0.003511  loss_rpn_loc: 0.01258  time: 2.9740  data_time: 0.1152  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:21:24 d2.utils.events]: \u001b[0m eta: 12:21:01  iter: 3359  total_loss: 0.1052  loss_cls: 0.02291  loss_box_reg: 0.05831  loss_rpn_cls: 0.002992  loss_rpn_loc: 0.01243  time: 2.9752  data_time: 0.0994  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:22:24 d2.utils.events]: \u001b[0m eta: 12:19:40  iter: 3379  total_loss: 0.0762  loss_cls: 0.01773  loss_box_reg: 0.04695  loss_rpn_cls: 0.002545  loss_rpn_loc: 0.01122  time: 2.9752  data_time: 0.1107  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:23:24 d2.utils.events]: \u001b[0m eta: 12:18:48  iter: 3399  total_loss: 0.08404  loss_cls: 0.01718  loss_box_reg: 0.03547  loss_rpn_cls: 0.003574  loss_rpn_loc: 0.01738  time: 2.9753  data_time: 0.1213  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:24:25 d2.utils.events]: \u001b[0m eta: 12:17:50  iter: 3419  total_loss: 0.09363  loss_cls: 0.02244  loss_box_reg: 0.04991  loss_rpn_cls: 0.003439  loss_rpn_loc: 0.01468  time: 2.9759  data_time: 0.1025  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:25:23 d2.utils.events]: \u001b[0m eta: 12:15:52  iter: 3439  total_loss: 0.07488  loss_cls: 0.01913  loss_box_reg: 0.04273  loss_rpn_cls: 0.002573  loss_rpn_loc: 0.01297  time: 2.9754  data_time: 0.0912  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:26:23 d2.utils.events]: \u001b[0m eta: 12:14:20  iter: 3459  total_loss: 0.06413  loss_cls: 0.01991  loss_box_reg: 0.03764  loss_rpn_cls: 0.002019  loss_rpn_loc: 0.009308  time: 2.9756  data_time: 0.1070  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:27:27 d2.utils.events]: \u001b[0m eta: 12:14:14  iter: 3479  total_loss: 0.06861  loss_cls: 0.01575  loss_box_reg: 0.03778  loss_rpn_cls: 0.002209  loss_rpn_loc: 0.01134  time: 2.9769  data_time: 0.1055  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:28:27 d2.utils.events]: \u001b[0m eta: 12:12:39  iter: 3499  total_loss: 0.09855  loss_cls: 0.01989  loss_box_reg: 0.05543  loss_rpn_cls: 0.003669  loss_rpn_loc: 0.01576  time: 2.9771  data_time: 0.1118  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:29:28 d2.utils.events]: \u001b[0m eta: 12:12:04  iter: 3519  total_loss: 0.0836  loss_cls: 0.01657  loss_box_reg: 0.03704  loss_rpn_cls: 0.003176  loss_rpn_loc: 0.01488  time: 2.9775  data_time: 0.1172  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:30:30 d2.utils.events]: \u001b[0m eta: 12:11:14  iter: 3539  total_loss: 0.0915  loss_cls: 0.02131  loss_box_reg: 0.05297  loss_rpn_cls: 0.002161  loss_rpn_loc: 0.01233  time: 2.9782  data_time: 0.0826  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:31:31 d2.utils.events]: \u001b[0m eta: 12:10:13  iter: 3559  total_loss: 0.09274  loss_cls: 0.02132  loss_box_reg: 0.04443  loss_rpn_cls: 0.001793  loss_rpn_loc: 0.0127  time: 2.9785  data_time: 0.1048  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:32:30 d2.utils.events]: \u001b[0m eta: 12:09:19  iter: 3579  total_loss: 0.07424  loss_cls: 0.01813  loss_box_reg: 0.04203  loss_rpn_cls: 0.002178  loss_rpn_loc: 0.01396  time: 2.9785  data_time: 0.1107  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:33:33 d2.utils.events]: \u001b[0m eta: 12:08:43  iter: 3599  total_loss: 0.08117  loss_cls: 0.01936  loss_box_reg: 0.04617  loss_rpn_cls: 0.002511  loss_rpn_loc: 0.01359  time: 2.9792  data_time: 0.0938  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:34:36 d2.utils.events]: \u001b[0m eta: 12:07:55  iter: 3619  total_loss: 0.08776  loss_cls: 0.02022  loss_box_reg: 0.04818  loss_rpn_cls: 0.00271  loss_rpn_loc: 0.01656  time: 2.9801  data_time: 0.0964  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:35:35 d2.utils.events]: \u001b[0m eta: 12:06:33  iter: 3639  total_loss: 0.07981  loss_cls: 0.02017  loss_box_reg: 0.04379  loss_rpn_cls: 0.001721  loss_rpn_loc: 0.01218  time: 2.9800  data_time: 0.1084  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:36:35 d2.utils.events]: \u001b[0m eta: 12:05:41  iter: 3659  total_loss: 0.07047  loss_cls: 0.01459  loss_box_reg: 0.03667  loss_rpn_cls: 0.002933  loss_rpn_loc: 0.01427  time: 2.9800  data_time: 0.1084  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:37:36 d2.utils.events]: \u001b[0m eta: 12:04:09  iter: 3679  total_loss: 0.08593  loss_cls: 0.02174  loss_box_reg: 0.04594  loss_rpn_cls: 0.002444  loss_rpn_loc: 0.01744  time: 2.9804  data_time: 0.0969  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:38:32 d2.utils.events]: \u001b[0m eta: 12:03:02  iter: 3699  total_loss: 0.07458  loss_cls: 0.01984  loss_box_reg: 0.04362  loss_rpn_cls: 0.003219  loss_rpn_loc: 0.009733  time: 2.9795  data_time: 0.1100  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:39:30 d2.utils.events]: \u001b[0m eta: 12:01:02  iter: 3719  total_loss: 0.06512  loss_cls: 0.01644  loss_box_reg: 0.03532  loss_rpn_cls: 0.002312  loss_rpn_loc: 0.01403  time: 2.9792  data_time: 0.0979  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:40:31 d2.utils.events]: \u001b[0m eta: 11:59:37  iter: 3739  total_loss: 0.08857  loss_cls: 0.01977  loss_box_reg: 0.04471  loss_rpn_cls: 0.001888  loss_rpn_loc: 0.01362  time: 2.9795  data_time: 0.1074  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:41:34 d2.utils.events]: \u001b[0m eta: 11:59:11  iter: 3759  total_loss: 0.07163  loss_cls: 0.01831  loss_box_reg: 0.04098  loss_rpn_cls: 0.002374  loss_rpn_loc: 0.01131  time: 2.9804  data_time: 0.0791  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:42:35 d2.utils.events]: \u001b[0m eta: 11:57:49  iter: 3779  total_loss: 0.06651  loss_cls: 0.01636  loss_box_reg: 0.03657  loss_rpn_cls: 0.001967  loss_rpn_loc: 0.01127  time: 2.9808  data_time: 0.1109  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:43:33 d2.utils.events]: \u001b[0m eta: 11:55:25  iter: 3799  total_loss: 0.06581  loss_cls: 0.01643  loss_box_reg: 0.03562  loss_rpn_cls: 0.002338  loss_rpn_loc: 0.01109  time: 2.9805  data_time: 0.1209  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:44:36 d2.utils.events]: \u001b[0m eta: 11:55:04  iter: 3819  total_loss: 0.07936  loss_cls: 0.01739  loss_box_reg: 0.04211  loss_rpn_cls: 0.002413  loss_rpn_loc: 0.01429  time: 2.9811  data_time: 0.0958  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:45:38 d2.utils.events]: \u001b[0m eta: 11:54:35  iter: 3839  total_loss: 0.0689  loss_cls: 0.01491  loss_box_reg: 0.03493  loss_rpn_cls: 0.002462  loss_rpn_loc: 0.01419  time: 2.9819  data_time: 0.1203  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:46:40 d2.utils.events]: \u001b[0m eta: 11:53:55  iter: 3859  total_loss: 0.07072  loss_cls: 0.01686  loss_box_reg: 0.0432  loss_rpn_cls: 0.002109  loss_rpn_loc: 0.01021  time: 2.9824  data_time: 0.1005  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:47:41 d2.utils.events]: \u001b[0m eta: 11:52:42  iter: 3879  total_loss: 0.0725  loss_cls: 0.0171  loss_box_reg: 0.03649  loss_rpn_cls: 0.001863  loss_rpn_loc: 0.01426  time: 2.9828  data_time: 0.1119  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:48:43 d2.utils.events]: \u001b[0m eta: 11:52:19  iter: 3899  total_loss: 0.0903  loss_cls: 0.01977  loss_box_reg: 0.0456  loss_rpn_cls: 0.002226  loss_rpn_loc: 0.01538  time: 2.9835  data_time: 0.1083  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:49:44 d2.utils.events]: \u001b[0m eta: 11:51:48  iter: 3919  total_loss: 0.0796  loss_cls: 0.01723  loss_box_reg: 0.03893  loss_rpn_cls: 0.002129  loss_rpn_loc: 0.01243  time: 2.9839  data_time: 0.1073  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:50:44 d2.utils.events]: \u001b[0m eta: 11:50:02  iter: 3939  total_loss: 0.07964  loss_cls: 0.02037  loss_box_reg: 0.05457  loss_rpn_cls: 0.001891  loss_rpn_loc: 0.01211  time: 2.9837  data_time: 0.1014  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:51:45 d2.utils.events]: \u001b[0m eta: 11:49:08  iter: 3959  total_loss: 0.06258  loss_cls: 0.01618  loss_box_reg: 0.03431  loss_rpn_cls: 0.001985  loss_rpn_loc: 0.01077  time: 2.9841  data_time: 0.1141  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:52:44 d2.utils.events]: \u001b[0m eta: 11:47:27  iter: 3979  total_loss: 0.06735  loss_cls: 0.01804  loss_box_reg: 0.03788  loss_rpn_cls: 0.002119  loss_rpn_loc: 0.01253  time: 2.9840  data_time: 0.1007  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:53:45 d2.utils.events]: \u001b[0m eta: 11:46:26  iter: 3999  total_loss: 0.0611  loss_cls: 0.01211  loss_box_reg: 0.02988  loss_rpn_cls: 0.001449  loss_rpn_loc: 0.01256  time: 2.9843  data_time: 0.0998  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:54:48 d2.utils.events]: \u001b[0m eta: 11:45:30  iter: 4019  total_loss: 0.07434  loss_cls: 0.0153  loss_box_reg: 0.04074  loss_rpn_cls: 0.002241  loss_rpn_loc: 0.01381  time: 2.9851  data_time: 0.1756  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:55:48 d2.utils.events]: \u001b[0m eta: 11:44:25  iter: 4039  total_loss: 0.08519  loss_cls: 0.01881  loss_box_reg: 0.0537  loss_rpn_cls: 0.001818  loss_rpn_loc: 0.01428  time: 2.9852  data_time: 0.0870  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:56:49 d2.utils.events]: \u001b[0m eta: 11:43:29  iter: 4059  total_loss: 0.06001  loss_cls: 0.0122  loss_box_reg: 0.03284  loss_rpn_cls: 0.001649  loss_rpn_loc: 0.01099  time: 2.9855  data_time: 0.1019  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:57:48 d2.utils.events]: \u001b[0m eta: 11:41:38  iter: 4079  total_loss: 0.08358  loss_cls: 0.01905  loss_box_reg: 0.04406  loss_rpn_cls: 0.002574  loss_rpn_loc: 0.01197  time: 2.9854  data_time: 0.1027  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:58:50 d2.utils.events]: \u001b[0m eta: 11:40:43  iter: 4099  total_loss: 0.0593  loss_cls: 0.01446  loss_box_reg: 0.02803  loss_rpn_cls: 0.001749  loss_rpn_loc: 0.01295  time: 2.9859  data_time: 0.0996  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 22:59:49 d2.utils.events]: \u001b[0m eta: 11:39:28  iter: 4119  total_loss: 0.07726  loss_cls: 0.01723  loss_box_reg: 0.04416  loss_rpn_cls: 0.001621  loss_rpn_loc: 0.01254  time: 2.9858  data_time: 0.1024  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:00:48 d2.utils.events]: \u001b[0m eta: 11:38:33  iter: 4139  total_loss: 0.07399  loss_cls: 0.01548  loss_box_reg: 0.03818  loss_rpn_cls: 0.001554  loss_rpn_loc: 0.01168  time: 2.9857  data_time: 0.1002  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:01:50 d2.utils.events]: \u001b[0m eta: 11:37:27  iter: 4159  total_loss: 0.07328  loss_cls: 0.01592  loss_box_reg: 0.03561  loss_rpn_cls: 0.002233  loss_rpn_loc: 0.01241  time: 2.9861  data_time: 0.1161  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:02:51 d2.utils.events]: \u001b[0m eta: 11:36:32  iter: 4179  total_loss: 0.07124  loss_cls: 0.01758  loss_box_reg: 0.03582  loss_rpn_cls: 0.00187  loss_rpn_loc: 0.01175  time: 2.9865  data_time: 0.1163  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:03:54 d2.utils.events]: \u001b[0m eta: 11:35:18  iter: 4199  total_loss: 0.07304  loss_cls: 0.01728  loss_box_reg: 0.04066  loss_rpn_cls: 0.002305  loss_rpn_loc: 0.01252  time: 2.9871  data_time: 0.1033  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:04:53 d2.utils.events]: \u001b[0m eta: 11:33:20  iter: 4219  total_loss: 0.05882  loss_cls: 0.01472  loss_box_reg: 0.03661  loss_rpn_cls: 0.001714  loss_rpn_loc: 0.009914  time: 2.9869  data_time: 0.1106  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:05:53 d2.utils.events]: \u001b[0m eta: 11:31:55  iter: 4239  total_loss: 0.06514  loss_cls: 0.01285  loss_box_reg: 0.03757  loss_rpn_cls: 0.001921  loss_rpn_loc: 0.01175  time: 2.9872  data_time: 0.0844  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:06:55 d2.utils.events]: \u001b[0m eta: 11:30:59  iter: 4259  total_loss: 0.07278  loss_cls: 0.01575  loss_box_reg: 0.03648  loss_rpn_cls: 0.001972  loss_rpn_loc: 0.01322  time: 2.9877  data_time: 0.1020  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:07:56 d2.utils.events]: \u001b[0m eta: 11:29:54  iter: 4279  total_loss: 0.08087  loss_cls: 0.01765  loss_box_reg: 0.04594  loss_rpn_cls: 0.002333  loss_rpn_loc: 0.01126  time: 2.9879  data_time: 0.1095  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:08:56 d2.utils.events]: \u001b[0m eta: 11:28:28  iter: 4299  total_loss: 0.07605  loss_cls: 0.01887  loss_box_reg: 0.04475  loss_rpn_cls: 0.001343  loss_rpn_loc: 0.01036  time: 2.9880  data_time: 0.1067  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:09:53 d2.utils.events]: \u001b[0m eta: 11:27:02  iter: 4319  total_loss: 0.04781  loss_cls: 0.01063  loss_box_reg: 0.02776  loss_rpn_cls: 0.000889  loss_rpn_loc: 0.007041  time: 2.9873  data_time: 0.1013  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:10:53 d2.utils.events]: \u001b[0m eta: 11:26:08  iter: 4339  total_loss: 0.06635  loss_cls: 0.01416  loss_box_reg: 0.03485  loss_rpn_cls: 0.002408  loss_rpn_loc: 0.01538  time: 2.9873  data_time: 0.1030  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:11:53 d2.utils.events]: \u001b[0m eta: 11:23:55  iter: 4359  total_loss: 0.0628  loss_cls: 0.01508  loss_box_reg: 0.03475  loss_rpn_cls: 0.001867  loss_rpn_loc: 0.01263  time: 2.9875  data_time: 0.1025  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:12:55 d2.utils.events]: \u001b[0m eta: 11:23:22  iter: 4379  total_loss: 0.07795  loss_cls: 0.0185  loss_box_reg: 0.04721  loss_rpn_cls: 0.001476  loss_rpn_loc: 0.01129  time: 2.9879  data_time: 0.0947  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:13:55 d2.utils.events]: \u001b[0m eta: 11:21:44  iter: 4399  total_loss: 0.06346  loss_cls: 0.01564  loss_box_reg: 0.03566  loss_rpn_cls: 0.00217  loss_rpn_loc: 0.01212  time: 2.9879  data_time: 0.0881  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:14:57 d2.utils.events]: \u001b[0m eta: 11:21:38  iter: 4419  total_loss: 0.0794  loss_cls: 0.01866  loss_box_reg: 0.04876  loss_rpn_cls: 0.002271  loss_rpn_loc: 0.0117  time: 2.9886  data_time: 0.1235  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:15:57 d2.utils.events]: \u001b[0m eta: 11:20:56  iter: 4439  total_loss: 0.07369  loss_cls: 0.01523  loss_box_reg: 0.04094  loss_rpn_cls: 0.001941  loss_rpn_loc: 0.01006  time: 2.9885  data_time: 0.0979  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:16:57 d2.utils.events]: \u001b[0m eta: 11:19:56  iter: 4459  total_loss: 0.06998  loss_cls: 0.01696  loss_box_reg: 0.03696  loss_rpn_cls: 0.00189  loss_rpn_loc: 0.01035  time: 2.9885  data_time: 0.0790  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:17:57 d2.utils.events]: \u001b[0m eta: 11:18:21  iter: 4479  total_loss: 0.06009  loss_cls: 0.0134  loss_box_reg: 0.03581  loss_rpn_cls: 0.002158  loss_rpn_loc: 0.009246  time: 2.9888  data_time: 0.1123  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:18:58 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /content/gdrive/MyDrive/fsdet-v/model_0004499.pth\n",
            "\u001b[32m[07/28 23:19:01 d2.utils.events]: \u001b[0m eta: 11:17:55  iter: 4499  total_loss: 0.07249  loss_cls: 0.01536  loss_box_reg: 0.04256  loss_rpn_cls: 0.002054  loss_rpn_loc: 0.01131  time: 2.9890  data_time: 0.1045  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:20:02 d2.utils.events]: \u001b[0m eta: 11:16:55  iter: 4519  total_loss: 0.06876  loss_cls: 0.01508  loss_box_reg: 0.03599  loss_rpn_cls: 0.002118  loss_rpn_loc: 0.0128  time: 2.9892  data_time: 0.0871  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:21:02 d2.utils.events]: \u001b[0m eta: 11:15:02  iter: 4539  total_loss: 0.07524  loss_cls: 0.01841  loss_box_reg: 0.03208  loss_rpn_cls: 0.002269  loss_rpn_loc: 0.01201  time: 2.9893  data_time: 0.0981  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:22:00 d2.utils.events]: \u001b[0m eta: 11:13:36  iter: 4559  total_loss: 0.07155  loss_cls: 0.01655  loss_box_reg: 0.03452  loss_rpn_cls: 0.001703  loss_rpn_loc: 0.01257  time: 2.9889  data_time: 0.1117  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:23:01 d2.utils.events]: \u001b[0m eta: 11:12:57  iter: 4579  total_loss: 0.06702  loss_cls: 0.01284  loss_box_reg: 0.03348  loss_rpn_cls: 0.001946  loss_rpn_loc: 0.01153  time: 2.9891  data_time: 0.0888  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:24:02 d2.utils.events]: \u001b[0m eta: 11:11:13  iter: 4599  total_loss: 0.07949  loss_cls: 0.0167  loss_box_reg: 0.0465  loss_rpn_cls: 0.002013  loss_rpn_loc: 0.01241  time: 2.9894  data_time: 0.1259  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:25:01 d2.utils.events]: \u001b[0m eta: 11:09:35  iter: 4619  total_loss: 0.07301  loss_cls: 0.01759  loss_box_reg: 0.0418  loss_rpn_cls: 0.002019  loss_rpn_loc: 0.01124  time: 2.9893  data_time: 0.1054  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:26:00 d2.utils.events]: \u001b[0m eta: 11:08:45  iter: 4639  total_loss: 0.08198  loss_cls: 0.01938  loss_box_reg: 0.04879  loss_rpn_cls: 0.002211  loss_rpn_loc: 0.01266  time: 2.9892  data_time: 0.1013  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:27:03 d2.utils.events]: \u001b[0m eta: 11:08:05  iter: 4659  total_loss: 0.06813  loss_cls: 0.0127  loss_box_reg: 0.03208  loss_rpn_cls: 0.001239  loss_rpn_loc: 0.01237  time: 2.9897  data_time: 0.0916  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:27:59 d2.utils.events]: \u001b[0m eta: 11:06:26  iter: 4679  total_loss: 0.0567  loss_cls: 0.01342  loss_box_reg: 0.0319  loss_rpn_cls: 0.001615  loss_rpn_loc: 0.009728  time: 2.9890  data_time: 0.1158  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:28:58 d2.utils.events]: \u001b[0m eta: 11:05:41  iter: 4699  total_loss: 0.0631  loss_cls: 0.01478  loss_box_reg: 0.04194  loss_rpn_cls: 0.001437  loss_rpn_loc: 0.01025  time: 2.9889  data_time: 0.1178  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:30:00 d2.utils.events]: \u001b[0m eta: 11:04:51  iter: 4719  total_loss: 0.06949  loss_cls: 0.01613  loss_box_reg: 0.03728  loss_rpn_cls: 0.001538  loss_rpn_loc: 0.009433  time: 2.9894  data_time: 0.0898  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:31:00 d2.utils.events]: \u001b[0m eta: 11:04:00  iter: 4739  total_loss: 0.06269  loss_cls: 0.01471  loss_box_reg: 0.03853  loss_rpn_cls: 0.001945  loss_rpn_loc: 0.01302  time: 2.9894  data_time: 0.1003  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:32:01 d2.utils.events]: \u001b[0m eta: 11:02:28  iter: 4759  total_loss: 0.07597  loss_cls: 0.01706  loss_box_reg: 0.04213  loss_rpn_cls: 0.001678  loss_rpn_loc: 0.01097  time: 2.9896  data_time: 0.1120  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:33:02 d2.utils.events]: \u001b[0m eta: 11:01:23  iter: 4779  total_loss: 0.05796  loss_cls: 0.01412  loss_box_reg: 0.02993  loss_rpn_cls: 0.001758  loss_rpn_loc: 0.00989  time: 2.9899  data_time: 0.1087  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:34:03 d2.utils.events]: \u001b[0m eta: 11:00:43  iter: 4799  total_loss: 0.06761  loss_cls: 0.01354  loss_box_reg: 0.03386  loss_rpn_cls: 0.001487  loss_rpn_loc: 0.01181  time: 2.9901  data_time: 0.1053  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:35:03 d2.utils.events]: \u001b[0m eta: 10:59:59  iter: 4819  total_loss: 0.05546  loss_cls: 0.01411  loss_box_reg: 0.03036  loss_rpn_cls: 0.001568  loss_rpn_loc: 0.01182  time: 2.9902  data_time: 0.1148  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:36:04 d2.utils.events]: \u001b[0m eta: 10:58:42  iter: 4839  total_loss: 0.04719  loss_cls: 0.01116  loss_box_reg: 0.02544  loss_rpn_cls: 0.001387  loss_rpn_loc: 0.01187  time: 2.9903  data_time: 0.1098  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:37:04 d2.utils.events]: \u001b[0m eta: 10:57:49  iter: 4859  total_loss: 0.05935  loss_cls: 0.01186  loss_box_reg: 0.03687  loss_rpn_cls: 0.001252  loss_rpn_loc: 0.01258  time: 2.9904  data_time: 0.0913  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:38:05 d2.utils.events]: \u001b[0m eta: 10:56:59  iter: 4879  total_loss: 0.05192  loss_cls: 0.01493  loss_box_reg: 0.02716  loss_rpn_cls: 0.001588  loss_rpn_loc: 0.01238  time: 2.9907  data_time: 0.1118  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:39:06 d2.utils.events]: \u001b[0m eta: 10:56:07  iter: 4899  total_loss: 0.07834  loss_cls: 0.01852  loss_box_reg: 0.04276  loss_rpn_cls: 0.001789  loss_rpn_loc: 0.01109  time: 2.9909  data_time: 0.0830  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:40:09 d2.utils.events]: \u001b[0m eta: 10:55:18  iter: 4919  total_loss: 0.06569  loss_cls: 0.01536  loss_box_reg: 0.03544  loss_rpn_cls: 0.001502  loss_rpn_loc: 0.01363  time: 2.9915  data_time: 0.1058  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:41:10 d2.utils.events]: \u001b[0m eta: 10:54:16  iter: 4939  total_loss: 0.06001  loss_cls: 0.01271  loss_box_reg: 0.0345  loss_rpn_cls: 0.001576  loss_rpn_loc: 0.01059  time: 2.9917  data_time: 0.1039  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:42:09 d2.utils.events]: \u001b[0m eta: 10:53:04  iter: 4959  total_loss: 0.05774  loss_cls: 0.01163  loss_box_reg: 0.03075  loss_rpn_cls: 0.001484  loss_rpn_loc: 0.01142  time: 2.9917  data_time: 0.0971  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:43:10 d2.utils.events]: \u001b[0m eta: 10:52:12  iter: 4979  total_loss: 0.06513  loss_cls: 0.01524  loss_box_reg: 0.03625  loss_rpn_cls: 0.001184  loss_rpn_loc: 0.00986  time: 2.9918  data_time: 0.1762  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:44:08 d2.utils.events]: \u001b[0m eta: 10:50:44  iter: 4999  total_loss: 0.049  loss_cls: 0.01312  loss_box_reg: 0.02712  loss_rpn_cls: 0.001197  loss_rpn_loc: 0.009702  time: 2.9915  data_time: 0.0919  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:45:12 d2.utils.events]: \u001b[0m eta: 10:49:44  iter: 5019  total_loss: 0.05429  loss_cls: 0.01277  loss_box_reg: 0.03068  loss_rpn_cls: 0.001662  loss_rpn_loc: 0.009996  time: 2.9922  data_time: 0.1327  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:46:12 d2.utils.events]: \u001b[0m eta: 10:49:07  iter: 5039  total_loss: 0.06086  loss_cls: 0.01188  loss_box_reg: 0.0289  loss_rpn_cls: 0.002258  loss_rpn_loc: 0.01159  time: 2.9923  data_time: 0.0996  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:47:12 d2.utils.events]: \u001b[0m eta: 10:48:17  iter: 5059  total_loss: 0.05712  loss_cls: 0.01319  loss_box_reg: 0.03204  loss_rpn_cls: 0.001706  loss_rpn_loc: 0.01082  time: 2.9924  data_time: 0.1046  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:48:11 d2.utils.events]: \u001b[0m eta: 10:47:30  iter: 5079  total_loss: 0.06111  loss_cls: 0.01368  loss_box_reg: 0.02561  loss_rpn_cls: 0.002752  loss_rpn_loc: 0.00971  time: 2.9921  data_time: 0.0967  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:49:11 d2.utils.events]: \u001b[0m eta: 10:46:17  iter: 5099  total_loss: 0.06658  loss_cls: 0.01508  loss_box_reg: 0.03377  loss_rpn_cls: 0.002224  loss_rpn_loc: 0.01077  time: 2.9923  data_time: 0.1092  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:50:11 d2.utils.events]: \u001b[0m eta: 10:45:37  iter: 5119  total_loss: 0.05104  loss_cls: 0.01146  loss_box_reg: 0.02663  loss_rpn_cls: 0.003285  loss_rpn_loc: 0.01358  time: 2.9923  data_time: 0.0910  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:51:13 d2.utils.events]: \u001b[0m eta: 10:44:51  iter: 5139  total_loss: 0.06458  loss_cls: 0.0157  loss_box_reg: 0.03423  loss_rpn_cls: 0.001751  loss_rpn_loc: 0.009726  time: 2.9927  data_time: 0.0921  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:52:14 d2.utils.events]: \u001b[0m eta: 10:43:49  iter: 5159  total_loss: 0.05232  loss_cls: 0.01396  loss_box_reg: 0.02841  loss_rpn_cls: 0.001264  loss_rpn_loc: 0.01052  time: 2.9929  data_time: 0.0930  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:53:14 d2.utils.events]: \u001b[0m eta: 10:42:44  iter: 5179  total_loss: 0.07081  loss_cls: 0.0151  loss_box_reg: 0.03812  loss_rpn_cls: 0.002078  loss_rpn_loc: 0.01327  time: 2.9930  data_time: 0.1115  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:54:16 d2.utils.events]: \u001b[0m eta: 10:41:44  iter: 5199  total_loss: 0.05886  loss_cls: 0.01277  loss_box_reg: 0.03054  loss_rpn_cls: 0.001226  loss_rpn_loc: 0.009118  time: 2.9933  data_time: 0.1099  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:55:14 d2.utils.events]: \u001b[0m eta: 10:40:44  iter: 5219  total_loss: 0.04253  loss_cls: 0.009348  loss_box_reg: 0.0238  loss_rpn_cls: 0.001296  loss_rpn_loc: 0.008761  time: 2.9931  data_time: 0.1016  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:56:13 d2.utils.events]: \u001b[0m eta: 10:39:11  iter: 5239  total_loss: 0.05123  loss_cls: 0.01094  loss_box_reg: 0.03428  loss_rpn_cls: 0.001383  loss_rpn_loc: 0.008933  time: 2.9928  data_time: 0.1148  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:57:14 d2.utils.events]: \u001b[0m eta: 10:37:40  iter: 5259  total_loss: 0.06314  loss_cls: 0.01374  loss_box_reg: 0.03437  loss_rpn_cls: 0.002051  loss_rpn_loc: 0.01061  time: 2.9929  data_time: 0.1088  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:58:12 d2.utils.events]: \u001b[0m eta: 10:36:30  iter: 5279  total_loss: 0.04918  loss_cls: 0.01015  loss_box_reg: 0.03284  loss_rpn_cls: 0.001736  loss_rpn_loc: 0.01134  time: 2.9927  data_time: 0.1205  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/28 23:59:12 d2.utils.events]: \u001b[0m eta: 10:35:24  iter: 5299  total_loss: 0.05855  loss_cls: 0.01268  loss_box_reg: 0.03425  loss_rpn_cls: 0.001505  loss_rpn_loc: 0.009904  time: 2.9926  data_time: 0.0987  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:00:11 d2.utils.events]: \u001b[0m eta: 10:34:39  iter: 5319  total_loss: 0.06613  loss_cls: 0.01196  loss_box_reg: 0.03066  loss_rpn_cls: 0.001942  loss_rpn_loc: 0.01025  time: 2.9925  data_time: 0.0927  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:01:11 d2.utils.events]: \u001b[0m eta: 10:33:42  iter: 5339  total_loss: 0.0493  loss_cls: 0.01136  loss_box_reg: 0.02618  loss_rpn_cls: 0.001017  loss_rpn_loc: 0.009022  time: 2.9926  data_time: 0.0986  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:02:10 d2.utils.events]: \u001b[0m eta: 10:32:42  iter: 5359  total_loss: 0.05828  loss_cls: 0.01229  loss_box_reg: 0.03085  loss_rpn_cls: 0.0009955  loss_rpn_loc: 0.009823  time: 2.9925  data_time: 0.0894  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:03:08 d2.utils.events]: \u001b[0m eta: 10:31:30  iter: 5379  total_loss: 0.05775  loss_cls: 0.01265  loss_box_reg: 0.03298  loss_rpn_cls: 0.002016  loss_rpn_loc: 0.009928  time: 2.9920  data_time: 0.1101  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:04:06 d2.utils.events]: \u001b[0m eta: 10:30:36  iter: 5399  total_loss: 0.05309  loss_cls: 0.01026  loss_box_reg: 0.03014  loss_rpn_cls: 0.00163  loss_rpn_loc: 0.0116  time: 2.9917  data_time: 0.0941  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:05:07 d2.utils.events]: \u001b[0m eta: 10:29:30  iter: 5419  total_loss: 0.05012  loss_cls: 0.01112  loss_box_reg: 0.02743  loss_rpn_cls: 0.001077  loss_rpn_loc: 0.008683  time: 2.9919  data_time: 0.1150  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:06:06 d2.utils.events]: \u001b[0m eta: 10:28:51  iter: 5439  total_loss: 0.06595  loss_cls: 0.01409  loss_box_reg: 0.03991  loss_rpn_cls: 0.001236  loss_rpn_loc: 0.01018  time: 2.9918  data_time: 0.0898  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:07:06 d2.utils.events]: \u001b[0m eta: 10:28:02  iter: 5459  total_loss: 0.04321  loss_cls: 0.009492  loss_box_reg: 0.02242  loss_rpn_cls: 0.001718  loss_rpn_loc: 0.01288  time: 2.9918  data_time: 0.1136  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:08:07 d2.utils.events]: \u001b[0m eta: 10:27:14  iter: 5479  total_loss: 0.05779  loss_cls: 0.01289  loss_box_reg: 0.03285  loss_rpn_cls: 0.001498  loss_rpn_loc: 0.01025  time: 2.9920  data_time: 0.1305  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:09:08 d2.utils.events]: \u001b[0m eta: 10:25:42  iter: 5499  total_loss: 0.05204  loss_cls: 0.01139  loss_box_reg: 0.03059  loss_rpn_cls: 0.001591  loss_rpn_loc: 0.01212  time: 2.9922  data_time: 0.1063  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:10:11 d2.utils.events]: \u001b[0m eta: 10:25:02  iter: 5519  total_loss: 0.03663  loss_cls: 0.008079  loss_box_reg: 0.01684  loss_rpn_cls: 0.001419  loss_rpn_loc: 0.01017  time: 2.9927  data_time: 0.1727  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:11:13 d2.utils.events]: \u001b[0m eta: 10:24:14  iter: 5539  total_loss: 0.05923  loss_cls: 0.01053  loss_box_reg: 0.02652  loss_rpn_cls: 0.001631  loss_rpn_loc: 0.01509  time: 2.9933  data_time: 0.1030  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:12:14 d2.utils.events]: \u001b[0m eta: 10:23:21  iter: 5559  total_loss: 0.05123  loss_cls: 0.01202  loss_box_reg: 0.02747  loss_rpn_cls: 0.001619  loss_rpn_loc: 0.01004  time: 2.9934  data_time: 0.1052  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:13:14 d2.utils.events]: \u001b[0m eta: 10:22:21  iter: 5579  total_loss: 0.0696  loss_cls: 0.01566  loss_box_reg: 0.03613  loss_rpn_cls: 0.001218  loss_rpn_loc: 0.01069  time: 2.9935  data_time: 0.1184  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:14:14 d2.utils.events]: \u001b[0m eta: 10:21:28  iter: 5599  total_loss: 0.04567  loss_cls: 0.009146  loss_box_reg: 0.02431  loss_rpn_cls: 0.001366  loss_rpn_loc: 0.009935  time: 2.9935  data_time: 0.1038  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:15:13 d2.utils.events]: \u001b[0m eta: 10:20:21  iter: 5619  total_loss: 0.05518  loss_cls: 0.01252  loss_box_reg: 0.03053  loss_rpn_cls: 0.001087  loss_rpn_loc: 0.008097  time: 2.9932  data_time: 0.1078  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:16:13 d2.utils.events]: \u001b[0m eta: 10:19:27  iter: 5639  total_loss: 0.05023  loss_cls: 0.01141  loss_box_reg: 0.02023  loss_rpn_cls: 0.001534  loss_rpn_loc: 0.00894  time: 2.9933  data_time: 0.1215  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:17:13 d2.utils.events]: \u001b[0m eta: 10:18:10  iter: 5659  total_loss: 0.05195  loss_cls: 0.01294  loss_box_reg: 0.03029  loss_rpn_cls: 0.0009954  loss_rpn_loc: 0.01037  time: 2.9933  data_time: 0.0846  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:18:15 d2.utils.events]: \u001b[0m eta: 10:17:43  iter: 5679  total_loss: 0.05151  loss_cls: 0.01182  loss_box_reg: 0.02917  loss_rpn_cls: 0.001585  loss_rpn_loc: 0.00909  time: 2.9936  data_time: 0.1141  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:19:16 d2.utils.events]: \u001b[0m eta: 10:17:42  iter: 5699  total_loss: 0.05701  loss_cls: 0.01001  loss_box_reg: 0.03216  loss_rpn_cls: 0.001348  loss_rpn_loc: 0.01083  time: 2.9938  data_time: 0.0916  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:20:16 d2.utils.events]: \u001b[0m eta: 10:16:43  iter: 5719  total_loss: 0.05506  loss_cls: 0.01098  loss_box_reg: 0.03135  loss_rpn_cls: 0.001082  loss_rpn_loc: 0.009459  time: 2.9940  data_time: 0.1105  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:21:15 d2.utils.events]: \u001b[0m eta: 10:15:41  iter: 5739  total_loss: 0.05939  loss_cls: 0.01317  loss_box_reg: 0.03511  loss_rpn_cls: 0.001338  loss_rpn_loc: 0.01034  time: 2.9938  data_time: 0.0867  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:22:18 d2.utils.events]: \u001b[0m eta: 10:14:44  iter: 5759  total_loss: 0.04683  loss_cls: 0.01205  loss_box_reg: 0.02073  loss_rpn_cls: 0.001179  loss_rpn_loc: 0.01199  time: 2.9943  data_time: 0.0950  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:23:16 d2.utils.events]: \u001b[0m eta: 10:13:07  iter: 5779  total_loss: 0.05612  loss_cls: 0.01378  loss_box_reg: 0.03494  loss_rpn_cls: 0.001406  loss_rpn_loc: 0.009956  time: 2.9940  data_time: 0.0889  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:24:15 d2.utils.events]: \u001b[0m eta: 10:11:53  iter: 5799  total_loss: 0.05672  loss_cls: 0.0092  loss_box_reg: 0.02976  loss_rpn_cls: 0.001682  loss_rpn_loc: 0.009686  time: 2.9938  data_time: 0.1089  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:25:14 d2.utils.events]: \u001b[0m eta: 10:10:35  iter: 5819  total_loss: 0.04376  loss_cls: 0.009412  loss_box_reg: 0.02105  loss_rpn_cls: 0.001146  loss_rpn_loc: 0.008564  time: 2.9937  data_time: 0.1099  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:26:17 d2.utils.events]: \u001b[0m eta: 10:09:55  iter: 5839  total_loss: 0.04475  loss_cls: 0.008538  loss_box_reg: 0.02059  loss_rpn_cls: 0.001689  loss_rpn_loc: 0.01002  time: 2.9942  data_time: 0.1052  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:27:16 d2.utils.events]: \u001b[0m eta: 10:08:42  iter: 5859  total_loss: 0.05704  loss_cls: 0.01283  loss_box_reg: 0.03374  loss_rpn_cls: 0.001661  loss_rpn_loc: 0.0117  time: 2.9941  data_time: 0.1119  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:28:18 d2.utils.events]: \u001b[0m eta: 10:07:44  iter: 5879  total_loss: 0.04862  loss_cls: 0.009111  loss_box_reg: 0.02467  loss_rpn_cls: 0.001721  loss_rpn_loc: 0.01406  time: 2.9943  data_time: 0.1097  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:29:17 d2.utils.events]: \u001b[0m eta: 10:06:13  iter: 5899  total_loss: 0.04798  loss_cls: 0.0108  loss_box_reg: 0.0264  loss_rpn_cls: 0.001141  loss_rpn_loc: 0.00999  time: 2.9943  data_time: 0.1055  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:30:20 d2.utils.events]: \u001b[0m eta: 10:05:11  iter: 5919  total_loss: 0.05807  loss_cls: 0.01157  loss_box_reg: 0.03346  loss_rpn_cls: 0.001208  loss_rpn_loc: 0.01112  time: 2.9947  data_time: 0.0953  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:31:20 d2.utils.events]: \u001b[0m eta: 10:04:10  iter: 5939  total_loss: 0.05611  loss_cls: 0.01024  loss_box_reg: 0.02899  loss_rpn_cls: 0.001314  loss_rpn_loc: 0.01137  time: 2.9948  data_time: 0.1166  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:32:20 d2.utils.events]: \u001b[0m eta: 10:03:10  iter: 5959  total_loss: 0.04558  loss_cls: 0.01133  loss_box_reg: 0.02478  loss_rpn_cls: 0.001016  loss_rpn_loc: 0.007449  time: 2.9948  data_time: 0.1009  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:33:21 d2.utils.events]: \u001b[0m eta: 10:02:38  iter: 5979  total_loss: 0.05032  loss_cls: 0.01075  loss_box_reg: 0.02591  loss_rpn_cls: 0.001741  loss_rpn_loc: 0.009904  time: 2.9951  data_time: 0.1134  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:34:24 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /content/gdrive/MyDrive/fsdet-v/model_0005999.pth\n",
            "\u001b[32m[07/29 00:34:26 d2.utils.events]: \u001b[0m eta: 10:02:04  iter: 5999  total_loss: 0.05601  loss_cls: 0.01187  loss_box_reg: 0.03203  loss_rpn_cls: 0.001141  loss_rpn_loc: 0.01013  time: 2.9954  data_time: 0.1155  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:35:26 d2.utils.events]: \u001b[0m eta: 10:00:57  iter: 6019  total_loss: 0.05417  loss_cls: 0.01075  loss_box_reg: 0.03019  loss_rpn_cls: 0.001179  loss_rpn_loc: 0.01086  time: 2.9955  data_time: 0.0995  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:36:26 d2.utils.events]: \u001b[0m eta: 9:59:40  iter: 6039  total_loss: 0.05276  loss_cls: 0.009452  loss_box_reg: 0.02461  loss_rpn_cls: 0.00121  loss_rpn_loc: 0.01372  time: 2.9954  data_time: 0.1041  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:37:27 d2.utils.events]: \u001b[0m eta: 9:58:57  iter: 6059  total_loss: 0.0403  loss_cls: 0.008674  loss_box_reg: 0.01949  loss_rpn_cls: 0.001046  loss_rpn_loc: 0.008814  time: 2.9957  data_time: 0.1645  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:38:27 d2.utils.events]: \u001b[0m eta: 9:58:04  iter: 6079  total_loss: 0.05019  loss_cls: 0.009507  loss_box_reg: 0.02653  loss_rpn_cls: 0.001064  loss_rpn_loc: 0.009736  time: 2.9956  data_time: 0.1109  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:39:28 d2.utils.events]: \u001b[0m eta: 9:57:00  iter: 6099  total_loss: 0.0583  loss_cls: 0.01049  loss_box_reg: 0.03345  loss_rpn_cls: 0.001141  loss_rpn_loc: 0.0106  time: 2.9958  data_time: 0.1069  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:40:26 d2.utils.events]: \u001b[0m eta: 9:55:56  iter: 6119  total_loss: 0.06092  loss_cls: 0.01366  loss_box_reg: 0.03332  loss_rpn_cls: 0.00112  loss_rpn_loc: 0.009982  time: 2.9956  data_time: 0.1102  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:41:24 d2.utils.events]: \u001b[0m eta: 9:54:03  iter: 6139  total_loss: 0.05991  loss_cls: 0.01224  loss_box_reg: 0.03378  loss_rpn_cls: 0.001197  loss_rpn_loc: 0.009216  time: 2.9951  data_time: 0.0973  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:42:23 d2.utils.events]: \u001b[0m eta: 9:53:03  iter: 6159  total_loss: 0.04933  loss_cls: 0.01129  loss_box_reg: 0.02632  loss_rpn_cls: 0.0005633  loss_rpn_loc: 0.007976  time: 2.9950  data_time: 0.0913  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:43:25 d2.utils.events]: \u001b[0m eta: 9:52:28  iter: 6179  total_loss: 0.05363  loss_cls: 0.01059  loss_box_reg: 0.03344  loss_rpn_cls: 0.0009009  loss_rpn_loc: 0.00895  time: 2.9953  data_time: 0.0911  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:44:26 d2.utils.events]: \u001b[0m eta: 9:51:32  iter: 6199  total_loss: 0.0546  loss_cls: 0.01425  loss_box_reg: 0.0295  loss_rpn_cls: 0.001024  loss_rpn_loc: 0.008798  time: 2.9956  data_time: 0.1145  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:45:27 d2.utils.events]: \u001b[0m eta: 9:50:35  iter: 6219  total_loss: 0.04424  loss_cls: 0.00938  loss_box_reg: 0.02587  loss_rpn_cls: 0.001224  loss_rpn_loc: 0.00808  time: 2.9957  data_time: 0.1552  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:46:29 d2.utils.events]: \u001b[0m eta: 9:50:12  iter: 6239  total_loss: 0.05841  loss_cls: 0.01203  loss_box_reg: 0.02974  loss_rpn_cls: 0.001078  loss_rpn_loc: 0.01125  time: 2.9961  data_time: 0.0995  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:47:28 d2.utils.events]: \u001b[0m eta: 9:49:12  iter: 6259  total_loss: 0.05064  loss_cls: 0.01324  loss_box_reg: 0.02628  loss_rpn_cls: 0.001148  loss_rpn_loc: 0.008552  time: 2.9959  data_time: 0.0973  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:48:29 d2.utils.events]: \u001b[0m eta: 9:48:27  iter: 6279  total_loss: 0.05835  loss_cls: 0.01317  loss_box_reg: 0.03315  loss_rpn_cls: 0.001159  loss_rpn_loc: 0.01197  time: 2.9961  data_time: 0.1033  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:49:32 d2.utils.events]: \u001b[0m eta: 9:47:31  iter: 6299  total_loss: 0.0476  loss_cls: 0.01026  loss_box_reg: 0.02557  loss_rpn_cls: 0.001103  loss_rpn_loc: 0.009508  time: 2.9966  data_time: 0.1703  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:50:30 d2.utils.events]: \u001b[0m eta: 9:46:23  iter: 6319  total_loss: 0.06035  loss_cls: 0.01197  loss_box_reg: 0.03653  loss_rpn_cls: 0.001205  loss_rpn_loc: 0.01112  time: 2.9963  data_time: 0.0981  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:51:32 d2.utils.events]: \u001b[0m eta: 9:45:22  iter: 6339  total_loss: 0.06682  loss_cls: 0.01331  loss_box_reg: 0.03769  loss_rpn_cls: 0.001708  loss_rpn_loc: 0.01277  time: 2.9965  data_time: 0.1188  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:52:31 d2.utils.events]: \u001b[0m eta: 9:44:32  iter: 6359  total_loss: 0.04636  loss_cls: 0.009754  loss_box_reg: 0.02428  loss_rpn_cls: 0.001154  loss_rpn_loc: 0.007118  time: 2.9965  data_time: 0.1080  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:53:32 d2.utils.events]: \u001b[0m eta: 9:43:51  iter: 6379  total_loss: 0.0472  loss_cls: 0.01165  loss_box_reg: 0.02512  loss_rpn_cls: 0.001152  loss_rpn_loc: 0.01024  time: 2.9966  data_time: 0.1022  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:54:33 d2.utils.events]: \u001b[0m eta: 9:43:12  iter: 6399  total_loss: 0.04849  loss_cls: 0.01058  loss_box_reg: 0.02574  loss_rpn_cls: 0.001698  loss_rpn_loc: 0.01018  time: 2.9967  data_time: 0.0811  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:55:37 d2.utils.events]: \u001b[0m eta: 9:42:36  iter: 6419  total_loss: 0.05628  loss_cls: 0.01108  loss_box_reg: 0.03017  loss_rpn_cls: 0.0008073  loss_rpn_loc: 0.009491  time: 2.9973  data_time: 0.0953  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:56:37 d2.utils.events]: \u001b[0m eta: 9:41:16  iter: 6439  total_loss: 0.05331  loss_cls: 0.01009  loss_box_reg: 0.02625  loss_rpn_cls: 0.001049  loss_rpn_loc: 0.009396  time: 2.9974  data_time: 0.1139  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:57:38 d2.utils.events]: \u001b[0m eta: 9:40:35  iter: 6459  total_loss: 0.05361  loss_cls: 0.01129  loss_box_reg: 0.02745  loss_rpn_cls: 0.001264  loss_rpn_loc: 0.01025  time: 2.9975  data_time: 0.0974  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:58:39 d2.utils.events]: \u001b[0m eta: 9:39:20  iter: 6479  total_loss: 0.05135  loss_cls: 0.0118  loss_box_reg: 0.03228  loss_rpn_cls: 0.001541  loss_rpn_loc: 0.01324  time: 2.9977  data_time: 0.1280  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 00:59:41 d2.utils.events]: \u001b[0m eta: 9:38:39  iter: 6499  total_loss: 0.05446  loss_cls: 0.0113  loss_box_reg: 0.03135  loss_rpn_cls: 0.0007861  loss_rpn_loc: 0.008954  time: 2.9981  data_time: 0.1052  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:00:43 d2.utils.events]: \u001b[0m eta: 9:37:44  iter: 6519  total_loss: 0.0687  loss_cls: 0.01475  loss_box_reg: 0.03735  loss_rpn_cls: 0.001209  loss_rpn_loc: 0.009987  time: 2.9983  data_time: 0.1858  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:01:44 d2.utils.events]: \u001b[0m eta: 9:36:26  iter: 6539  total_loss: 0.0522  loss_cls: 0.0116  loss_box_reg: 0.02724  loss_rpn_cls: 0.001333  loss_rpn_loc: 0.01262  time: 2.9985  data_time: 0.0974  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:02:43 d2.utils.events]: \u001b[0m eta: 9:35:12  iter: 6559  total_loss: 0.04939  loss_cls: 0.009576  loss_box_reg: 0.02903  loss_rpn_cls: 0.00109  loss_rpn_loc: 0.007357  time: 2.9984  data_time: 0.1110  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:03:46 d2.utils.events]: \u001b[0m eta: 9:34:25  iter: 6579  total_loss: 0.05664  loss_cls: 0.0111  loss_box_reg: 0.02933  loss_rpn_cls: 0.0009923  loss_rpn_loc: 0.01048  time: 2.9989  data_time: 0.0892  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:04:49 d2.utils.events]: \u001b[0m eta: 9:33:49  iter: 6599  total_loss: 0.04682  loss_cls: 0.01211  loss_box_reg: 0.0263  loss_rpn_cls: 0.001393  loss_rpn_loc: 0.01092  time: 2.9993  data_time: 0.1312  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:05:48 d2.utils.events]: \u001b[0m eta: 9:32:55  iter: 6619  total_loss: 0.05219  loss_cls: 0.01057  loss_box_reg: 0.02853  loss_rpn_cls: 0.001401  loss_rpn_loc: 0.01046  time: 2.9992  data_time: 0.0892  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:06:48 d2.utils.events]: \u001b[0m eta: 9:31:36  iter: 6639  total_loss: 0.05312  loss_cls: 0.01244  loss_box_reg: 0.03322  loss_rpn_cls: 0.0008979  loss_rpn_loc: 0.007131  time: 2.9991  data_time: 0.1075  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:07:51 d2.utils.events]: \u001b[0m eta: 9:31:02  iter: 6659  total_loss: 0.04837  loss_cls: 0.01115  loss_box_reg: 0.02648  loss_rpn_cls: 0.0009605  loss_rpn_loc: 0.009224  time: 2.9996  data_time: 0.1086  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:08:52 d2.utils.events]: \u001b[0m eta: 9:30:06  iter: 6679  total_loss: 0.06041  loss_cls: 0.01298  loss_box_reg: 0.03699  loss_rpn_cls: 0.0009143  loss_rpn_loc: 0.009625  time: 2.9998  data_time: 0.0973  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:09:53 d2.utils.events]: \u001b[0m eta: 9:28:35  iter: 6699  total_loss: 0.04961  loss_cls: 0.009215  loss_box_reg: 0.02625  loss_rpn_cls: 0.001114  loss_rpn_loc: 0.009841  time: 2.9999  data_time: 0.0880  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:10:52 d2.utils.events]: \u001b[0m eta: 9:27:16  iter: 6719  total_loss: 0.05262  loss_cls: 0.01096  loss_box_reg: 0.0291  loss_rpn_cls: 0.001186  loss_rpn_loc: 0.01208  time: 2.9997  data_time: 0.1155  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:11:52 d2.utils.events]: \u001b[0m eta: 9:26:16  iter: 6739  total_loss: 0.04845  loss_cls: 0.01122  loss_box_reg: 0.02974  loss_rpn_cls: 0.0008679  loss_rpn_loc: 0.00793  time: 2.9997  data_time: 0.0953  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:12:55 d2.utils.events]: \u001b[0m eta: 9:25:29  iter: 6759  total_loss: 0.04651  loss_cls: 0.009613  loss_box_reg: 0.02309  loss_rpn_cls: 0.00133  loss_rpn_loc: 0.01286  time: 3.0002  data_time: 0.1745  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:13:54 d2.utils.events]: \u001b[0m eta: 9:24:33  iter: 6779  total_loss: 0.04941  loss_cls: 0.009986  loss_box_reg: 0.02505  loss_rpn_cls: 0.001206  loss_rpn_loc: 0.01142  time: 3.0000  data_time: 0.0985  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:14:54 d2.utils.events]: \u001b[0m eta: 9:23:44  iter: 6799  total_loss: 0.04112  loss_cls: 0.009807  loss_box_reg: 0.02584  loss_rpn_cls: 0.0006113  loss_rpn_loc: 0.007142  time: 3.0001  data_time: 0.0920  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:15:56 d2.utils.events]: \u001b[0m eta: 9:22:44  iter: 6819  total_loss: 0.05248  loss_cls: 0.009931  loss_box_reg: 0.0306  loss_rpn_cls: 0.0007452  loss_rpn_loc: 0.009841  time: 3.0003  data_time: 0.0962  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:16:55 d2.utils.events]: \u001b[0m eta: 9:21:08  iter: 6839  total_loss: 0.04164  loss_cls: 0.008393  loss_box_reg: 0.02151  loss_rpn_cls: 0.0008861  loss_rpn_loc: 0.008962  time: 3.0002  data_time: 0.0891  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:17:56 d2.utils.events]: \u001b[0m eta: 9:20:08  iter: 6859  total_loss: 0.0683  loss_cls: 0.01278  loss_box_reg: 0.03525  loss_rpn_cls: 0.001242  loss_rpn_loc: 0.01028  time: 3.0003  data_time: 0.1013  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:18:57 d2.utils.events]: \u001b[0m eta: 9:19:04  iter: 6879  total_loss: 0.05407  loss_cls: 0.0113  loss_box_reg: 0.0306  loss_rpn_cls: 0.001115  loss_rpn_loc: 0.01012  time: 3.0005  data_time: 0.0988  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:19:57 d2.utils.events]: \u001b[0m eta: 9:18:07  iter: 6899  total_loss: 0.03647  loss_cls: 0.00749  loss_box_reg: 0.01977  loss_rpn_cls: 0.001214  loss_rpn_loc: 0.008546  time: 3.0005  data_time: 0.1073  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:20:56 d2.utils.events]: \u001b[0m eta: 9:16:45  iter: 6919  total_loss: 0.04669  loss_cls: 0.008894  loss_box_reg: 0.025  loss_rpn_cls: 0.0005788  loss_rpn_loc: 0.007826  time: 3.0003  data_time: 0.1146  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:21:56 d2.utils.events]: \u001b[0m eta: 9:15:49  iter: 6939  total_loss: 0.0461  loss_cls: 0.01018  loss_box_reg: 0.02528  loss_rpn_cls: 0.0009568  loss_rpn_loc: 0.008625  time: 3.0003  data_time: 0.0969  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:22:56 d2.utils.events]: \u001b[0m eta: 9:15:10  iter: 6959  total_loss: 0.05605  loss_cls: 0.01219  loss_box_reg: 0.02987  loss_rpn_cls: 0.000812  loss_rpn_loc: 0.01005  time: 3.0003  data_time: 0.0986  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:23:58 d2.utils.events]: \u001b[0m eta: 9:14:10  iter: 6979  total_loss: 0.06527  loss_cls: 0.01254  loss_box_reg: 0.03649  loss_rpn_cls: 0.0008479  loss_rpn_loc: 0.008846  time: 3.0005  data_time: 0.1030  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:25:01 d2.utils.events]: \u001b[0m eta: 9:13:40  iter: 6999  total_loss: 0.03978  loss_cls: 0.009493  loss_box_reg: 0.02343  loss_rpn_cls: 0.0006489  loss_rpn_loc: 0.007766  time: 3.0011  data_time: 0.0997  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:26:03 d2.utils.events]: \u001b[0m eta: 9:12:58  iter: 7019  total_loss: 0.04602  loss_cls: 0.01008  loss_box_reg: 0.02745  loss_rpn_cls: 0.001487  loss_rpn_loc: 0.01072  time: 3.0013  data_time: 0.0933  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:27:06 d2.utils.events]: \u001b[0m eta: 9:12:14  iter: 7039  total_loss: 0.04961  loss_cls: 0.01085  loss_box_reg: 0.02504  loss_rpn_cls: 0.0009382  loss_rpn_loc: 0.00941  time: 3.0017  data_time: 0.1038  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:28:08 d2.utils.events]: \u001b[0m eta: 9:11:14  iter: 7059  total_loss: 0.05742  loss_cls: 0.01277  loss_box_reg: 0.03443  loss_rpn_cls: 0.0007534  loss_rpn_loc: 0.008013  time: 3.0020  data_time: 0.1074  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:29:09 d2.utils.events]: \u001b[0m eta: 9:10:25  iter: 7079  total_loss: 0.05202  loss_cls: 0.0142  loss_box_reg: 0.03103  loss_rpn_cls: 0.0009681  loss_rpn_loc: 0.006705  time: 3.0021  data_time: 0.0963  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:30:09 d2.utils.events]: \u001b[0m eta: 9:09:25  iter: 7099  total_loss: 0.04562  loss_cls: 0.008502  loss_box_reg: 0.02454  loss_rpn_cls: 0.00062  loss_rpn_loc: 0.008453  time: 3.0021  data_time: 0.1068  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:31:08 d2.utils.events]: \u001b[0m eta: 9:08:24  iter: 7119  total_loss: 0.0548  loss_cls: 0.01323  loss_box_reg: 0.0357  loss_rpn_cls: 0.0007429  loss_rpn_loc: 0.007069  time: 3.0020  data_time: 0.1053  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:32:10 d2.utils.events]: \u001b[0m eta: 9:07:48  iter: 7139  total_loss: 0.04609  loss_cls: 0.01084  loss_box_reg: 0.0261  loss_rpn_cls: 0.0006855  loss_rpn_loc: 0.008265  time: 3.0022  data_time: 0.1246  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:33:08 d2.utils.events]: \u001b[0m eta: 9:06:14  iter: 7159  total_loss: 0.0454  loss_cls: 0.011  loss_box_reg: 0.02788  loss_rpn_cls: 0.00085  loss_rpn_loc: 0.009133  time: 3.0019  data_time: 0.1083  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:34:08 d2.utils.events]: \u001b[0m eta: 9:04:43  iter: 7179  total_loss: 0.05494  loss_cls: 0.01228  loss_box_reg: 0.02991  loss_rpn_cls: 0.0009474  loss_rpn_loc: 0.0102  time: 3.0019  data_time: 0.0973  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:35:08 d2.utils.events]: \u001b[0m eta: 9:03:14  iter: 7199  total_loss: 0.04426  loss_cls: 0.009958  loss_box_reg: 0.02006  loss_rpn_cls: 0.0008198  loss_rpn_loc: 0.01029  time: 3.0019  data_time: 0.1007  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:36:06 d2.utils.events]: \u001b[0m eta: 9:02:04  iter: 7219  total_loss: 0.05362  loss_cls: 0.01251  loss_box_reg: 0.02963  loss_rpn_cls: 0.0006241  loss_rpn_loc: 0.008413  time: 3.0017  data_time: 0.0962  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:37:08 d2.utils.events]: \u001b[0m eta: 9:00:58  iter: 7239  total_loss: 0.04757  loss_cls: 0.009771  loss_box_reg: 0.02477  loss_rpn_cls: 0.000966  loss_rpn_loc: 0.01128  time: 3.0019  data_time: 0.0953  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:38:10 d2.utils.events]: \u001b[0m eta: 9:00:21  iter: 7259  total_loss: 0.04539  loss_cls: 0.008254  loss_box_reg: 0.02541  loss_rpn_cls: 0.0008178  loss_rpn_loc: 0.009488  time: 3.0023  data_time: 0.1156  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:39:11 d2.utils.events]: \u001b[0m eta: 8:59:21  iter: 7279  total_loss: 0.04009  loss_cls: 0.008332  loss_box_reg: 0.02326  loss_rpn_cls: 0.000662  loss_rpn_loc: 0.008824  time: 3.0024  data_time: 0.0961  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:40:12 d2.utils.events]: \u001b[0m eta: 8:58:06  iter: 7299  total_loss: 0.05443  loss_cls: 0.01085  loss_box_reg: 0.02691  loss_rpn_cls: 0.001155  loss_rpn_loc: 0.009637  time: 3.0025  data_time: 0.1587  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:41:13 d2.utils.events]: \u001b[0m eta: 8:57:34  iter: 7319  total_loss: 0.05341  loss_cls: 0.01196  loss_box_reg: 0.03073  loss_rpn_cls: 0.0008898  loss_rpn_loc: 0.008572  time: 3.0026  data_time: 0.0941  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:42:15 d2.utils.events]: \u001b[0m eta: 8:56:28  iter: 7339  total_loss: 0.04482  loss_cls: 0.008013  loss_box_reg: 0.02279  loss_rpn_cls: 0.0009566  loss_rpn_loc: 0.009937  time: 3.0028  data_time: 0.1012  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:43:14 d2.utils.events]: \u001b[0m eta: 8:55:05  iter: 7359  total_loss: 0.04473  loss_cls: 0.00913  loss_box_reg: 0.02622  loss_rpn_cls: 0.0009688  loss_rpn_loc: 0.009349  time: 3.0027  data_time: 0.0908  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:44:13 d2.utils.events]: \u001b[0m eta: 8:53:59  iter: 7379  total_loss: 0.04608  loss_cls: 0.01089  loss_box_reg: 0.02826  loss_rpn_cls: 0.0007254  loss_rpn_loc: 0.008206  time: 3.0026  data_time: 0.0936  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:45:13 d2.utils.events]: \u001b[0m eta: 8:52:59  iter: 7399  total_loss: 0.04211  loss_cls: 0.007914  loss_box_reg: 0.02329  loss_rpn_cls: 0.0005678  loss_rpn_loc: 0.007394  time: 3.0025  data_time: 0.0965  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:46:12 d2.utils.events]: \u001b[0m eta: 8:51:34  iter: 7419  total_loss: 0.05531  loss_cls: 0.009859  loss_box_reg: 0.02842  loss_rpn_cls: 0.0009036  loss_rpn_loc: 0.009784  time: 3.0025  data_time: 0.0999  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:47:10 d2.utils.events]: \u001b[0m eta: 8:50:29  iter: 7439  total_loss: 0.04308  loss_cls: 0.008689  loss_box_reg: 0.02291  loss_rpn_cls: 0.0005119  loss_rpn_loc: 0.007219  time: 3.0022  data_time: 0.0974  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:48:11 d2.utils.events]: \u001b[0m eta: 8:49:31  iter: 7459  total_loss: 0.04751  loss_cls: 0.01154  loss_box_reg: 0.02941  loss_rpn_cls: 0.0008222  loss_rpn_loc: 0.008311  time: 3.0023  data_time: 0.1013  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:49:14 d2.utils.events]: \u001b[0m eta: 8:48:46  iter: 7479  total_loss: 0.03759  loss_cls: 0.009093  loss_box_reg: 0.02019  loss_rpn_cls: 0.0008166  loss_rpn_loc: 0.008872  time: 3.0027  data_time: 0.0917  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:50:16 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /content/gdrive/MyDrive/fsdet-v/model_0007499.pth\n",
            "\u001b[32m[07/29 01:50:18 d2.utils.events]: \u001b[0m eta: 8:47:41  iter: 7499  total_loss: 0.04007  loss_cls: 0.008528  loss_box_reg: 0.02048  loss_rpn_cls: 0.0009508  loss_rpn_loc: 0.01064  time: 3.0029  data_time: 0.0984  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:51:20 d2.utils.events]: \u001b[0m eta: 8:46:41  iter: 7519  total_loss: 0.0505  loss_cls: 0.01177  loss_box_reg: 0.02875  loss_rpn_cls: 0.0008311  loss_rpn_loc: 0.008891  time: 3.0031  data_time: 0.1110  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:52:21 d2.utils.events]: \u001b[0m eta: 8:45:36  iter: 7539  total_loss: 0.04464  loss_cls: 0.009644  loss_box_reg: 0.02559  loss_rpn_cls: 0.001262  loss_rpn_loc: 0.007969  time: 3.0032  data_time: 0.1101  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:53:19 d2.utils.events]: \u001b[0m eta: 8:44:45  iter: 7559  total_loss: 0.0434  loss_cls: 0.009358  loss_box_reg: 0.02561  loss_rpn_cls: 0.0005649  loss_rpn_loc: 0.006282  time: 3.0029  data_time: 0.1167  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:54:19 d2.utils.events]: \u001b[0m eta: 8:43:19  iter: 7579  total_loss: 0.03814  loss_cls: 0.008009  loss_box_reg: 0.02306  loss_rpn_cls: 0.0007444  loss_rpn_loc: 0.006945  time: 3.0029  data_time: 0.0873  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:55:19 d2.utils.events]: \u001b[0m eta: 8:41:41  iter: 7599  total_loss: 0.03988  loss_cls: 0.009029  loss_box_reg: 0.02203  loss_rpn_cls: 0.0005705  loss_rpn_loc: 0.00763  time: 3.0029  data_time: 0.1075  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:56:20 d2.utils.events]: \u001b[0m eta: 8:41:22  iter: 7619  total_loss: 0.05024  loss_cls: 0.01055  loss_box_reg: 0.03144  loss_rpn_cls: 0.0005313  loss_rpn_loc: 0.00797  time: 3.0031  data_time: 0.1001  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:57:20 d2.utils.events]: \u001b[0m eta: 8:40:31  iter: 7639  total_loss: 0.05151  loss_cls: 0.01257  loss_box_reg: 0.03166  loss_rpn_cls: 0.0007968  loss_rpn_loc: 0.0102  time: 3.0030  data_time: 0.1043  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:58:22 d2.utils.events]: \u001b[0m eta: 8:39:26  iter: 7659  total_loss: 0.03946  loss_cls: 0.007613  loss_box_reg: 0.02306  loss_rpn_cls: 0.0009831  loss_rpn_loc: 0.007974  time: 3.0033  data_time: 0.1105  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 01:59:23 d2.utils.events]: \u001b[0m eta: 8:38:25  iter: 7679  total_loss: 0.06105  loss_cls: 0.01471  loss_box_reg: 0.03511  loss_rpn_cls: 0.0009819  loss_rpn_loc: 0.01094  time: 3.0034  data_time: 0.0913  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:00:25 d2.utils.events]: \u001b[0m eta: 8:37:32  iter: 7699  total_loss: 0.03548  loss_cls: 0.007456  loss_box_reg: 0.01774  loss_rpn_cls: 0.000797  loss_rpn_loc: 0.009701  time: 3.0036  data_time: 0.1029  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:01:24 d2.utils.events]: \u001b[0m eta: 8:36:28  iter: 7719  total_loss: 0.04839  loss_cls: 0.01085  loss_box_reg: 0.02527  loss_rpn_cls: 0.0008975  loss_rpn_loc: 0.007883  time: 3.0035  data_time: 0.0934  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:02:23 d2.utils.events]: \u001b[0m eta: 8:35:32  iter: 7739  total_loss: 0.04103  loss_cls: 0.00813  loss_box_reg: 0.02062  loss_rpn_cls: 0.0006694  loss_rpn_loc: 0.007284  time: 3.0034  data_time: 0.0955  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:03:24 d2.utils.events]: \u001b[0m eta: 8:34:24  iter: 7759  total_loss: 0.06011  loss_cls: 0.01121  loss_box_reg: 0.0305  loss_rpn_cls: 0.001242  loss_rpn_loc: 0.00977  time: 3.0035  data_time: 0.1100  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:04:25 d2.utils.events]: \u001b[0m eta: 8:33:41  iter: 7779  total_loss: 0.04321  loss_cls: 0.009016  loss_box_reg: 0.02328  loss_rpn_cls: 0.0008199  loss_rpn_loc: 0.008788  time: 3.0037  data_time: 0.1066  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:05:26 d2.utils.events]: \u001b[0m eta: 8:33:06  iter: 7799  total_loss: 0.05068  loss_cls: 0.009406  loss_box_reg: 0.02276  loss_rpn_cls: 0.001003  loss_rpn_loc: 0.01089  time: 3.0037  data_time: 0.1072  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:06:26 d2.utils.events]: \u001b[0m eta: 8:32:04  iter: 7819  total_loss: 0.05068  loss_cls: 0.01138  loss_box_reg: 0.03025  loss_rpn_cls: 0.0009532  loss_rpn_loc: 0.007739  time: 3.0037  data_time: 0.1038  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:07:24 d2.utils.events]: \u001b[0m eta: 8:31:13  iter: 7839  total_loss: 0.0525  loss_cls: 0.01029  loss_box_reg: 0.0295  loss_rpn_cls: 0.0008888  loss_rpn_loc: 0.009991  time: 3.0035  data_time: 0.1304  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:08:27 d2.utils.events]: \u001b[0m eta: 8:30:29  iter: 7859  total_loss: 0.04633  loss_cls: 0.00963  loss_box_reg: 0.02156  loss_rpn_cls: 0.0007767  loss_rpn_loc: 0.009808  time: 3.0038  data_time: 0.1297  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:09:29 d2.utils.events]: \u001b[0m eta: 8:29:26  iter: 7879  total_loss: 0.04739  loss_cls: 0.009681  loss_box_reg: 0.02529  loss_rpn_cls: 0.001121  loss_rpn_loc: 0.008458  time: 3.0040  data_time: 0.1569  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:10:30 d2.utils.events]: \u001b[0m eta: 8:28:30  iter: 7899  total_loss: 0.04639  loss_cls: 0.009065  loss_box_reg: 0.02502  loss_rpn_cls: 0.00136  loss_rpn_loc: 0.009969  time: 3.0042  data_time: 0.1265  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:11:31 d2.utils.events]: \u001b[0m eta: 8:27:59  iter: 7919  total_loss: 0.05007  loss_cls: 0.01173  loss_box_reg: 0.02554  loss_rpn_cls: 0.000678  loss_rpn_loc: 0.0101  time: 3.0043  data_time: 0.0907  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:12:31 d2.utils.events]: \u001b[0m eta: 8:26:52  iter: 7939  total_loss: 0.05185  loss_cls: 0.01079  loss_box_reg: 0.03092  loss_rpn_cls: 0.0005474  loss_rpn_loc: 0.007305  time: 3.0043  data_time: 0.1821  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:13:34 d2.utils.events]: \u001b[0m eta: 8:26:02  iter: 7959  total_loss: 0.06118  loss_cls: 0.01254  loss_box_reg: 0.03666  loss_rpn_cls: 0.0006096  loss_rpn_loc: 0.0107  time: 3.0046  data_time: 0.0996  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:14:31 d2.utils.events]: \u001b[0m eta: 8:24:36  iter: 7979  total_loss: 0.04826  loss_cls: 0.00978  loss_box_reg: 0.02796  loss_rpn_cls: 0.001299  loss_rpn_loc: 0.007714  time: 3.0043  data_time: 0.1056  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:15:35 d2.utils.events]: \u001b[0m eta: 8:23:23  iter: 7999  total_loss: 0.04466  loss_cls: 0.009931  loss_box_reg: 0.02536  loss_rpn_cls: 0.0008572  loss_rpn_loc: 0.007475  time: 3.0047  data_time: 0.1207  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:16:36 d2.utils.events]: \u001b[0m eta: 8:22:17  iter: 8019  total_loss: 0.04804  loss_cls: 0.01001  loss_box_reg: 0.02455  loss_rpn_cls: 0.0008609  loss_rpn_loc: 0.00852  time: 3.0049  data_time: 0.0988  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:17:35 d2.utils.events]: \u001b[0m eta: 8:20:47  iter: 8039  total_loss: 0.04228  loss_cls: 0.009665  loss_box_reg: 0.02693  loss_rpn_cls: 0.0009871  loss_rpn_loc: 0.00648  time: 3.0048  data_time: 0.1166  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:18:38 d2.utils.events]: \u001b[0m eta: 8:19:36  iter: 8059  total_loss: 0.0503  loss_cls: 0.01078  loss_box_reg: 0.02534  loss_rpn_cls: 0.00118  loss_rpn_loc: 0.01066  time: 3.0051  data_time: 0.1053  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:19:37 d2.utils.events]: \u001b[0m eta: 8:18:19  iter: 8079  total_loss: 0.04825  loss_cls: 0.01063  loss_box_reg: 0.02547  loss_rpn_cls: 0.0007503  loss_rpn_loc: 0.009894  time: 3.0049  data_time: 0.1240  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:20:38 d2.utils.events]: \u001b[0m eta: 8:17:19  iter: 8099  total_loss: 0.03261  loss_cls: 0.007326  loss_box_reg: 0.01639  loss_rpn_cls: 0.0008929  loss_rpn_loc: 0.007149  time: 3.0050  data_time: 0.0946  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:21:41 d2.utils.events]: \u001b[0m eta: 8:16:51  iter: 8119  total_loss: 0.04311  loss_cls: 0.007117  loss_box_reg: 0.02395  loss_rpn_cls: 0.0008786  loss_rpn_loc: 0.01043  time: 3.0054  data_time: 0.1079  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:22:39 d2.utils.events]: \u001b[0m eta: 8:15:44  iter: 8139  total_loss: 0.04283  loss_cls: 0.01013  loss_box_reg: 0.0268  loss_rpn_cls: 0.0005085  loss_rpn_loc: 0.006426  time: 3.0052  data_time: 0.1070  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:23:40 d2.utils.events]: \u001b[0m eta: 8:14:58  iter: 8159  total_loss: 0.04307  loss_cls: 0.00844  loss_box_reg: 0.02401  loss_rpn_cls: 0.001247  loss_rpn_loc: 0.007937  time: 3.0052  data_time: 0.0985  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:24:43 d2.utils.events]: \u001b[0m eta: 8:14:24  iter: 8179  total_loss: 0.04716  loss_cls: 0.01044  loss_box_reg: 0.02402  loss_rpn_cls: 0.001117  loss_rpn_loc: 0.01041  time: 3.0056  data_time: 0.1003  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:25:42 d2.utils.events]: \u001b[0m eta: 8:13:29  iter: 8199  total_loss: 0.04653  loss_cls: 0.008725  loss_box_reg: 0.02408  loss_rpn_cls: 0.0009737  loss_rpn_loc: 0.0108  time: 3.0056  data_time: 0.1199  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:26:45 d2.utils.events]: \u001b[0m eta: 8:13:08  iter: 8219  total_loss: 0.04195  loss_cls: 0.008749  loss_box_reg: 0.01995  loss_rpn_cls: 0.0008972  loss_rpn_loc: 0.009539  time: 3.0059  data_time: 0.0921  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:27:48 d2.utils.events]: \u001b[0m eta: 8:12:08  iter: 8239  total_loss: 0.04248  loss_cls: 0.008439  loss_box_reg: 0.02076  loss_rpn_cls: 0.00097  loss_rpn_loc: 0.01155  time: 3.0062  data_time: 0.1114  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:28:49 d2.utils.events]: \u001b[0m eta: 8:10:49  iter: 8259  total_loss: 0.04306  loss_cls: 0.00886  loss_box_reg: 0.02431  loss_rpn_cls: 0.0008229  loss_rpn_loc: 0.00904  time: 3.0063  data_time: 0.0840  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:29:50 d2.utils.events]: \u001b[0m eta: 8:09:46  iter: 8279  total_loss: 0.0411  loss_cls: 0.009271  loss_box_reg: 0.02415  loss_rpn_cls: 0.001049  loss_rpn_loc: 0.009432  time: 3.0065  data_time: 0.1087  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:30:52 d2.utils.events]: \u001b[0m eta: 8:08:51  iter: 8299  total_loss: 0.04808  loss_cls: 0.009186  loss_box_reg: 0.02842  loss_rpn_cls: 0.0007217  loss_rpn_loc: 0.008289  time: 3.0067  data_time: 0.0998  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:31:53 d2.utils.events]: \u001b[0m eta: 8:07:41  iter: 8319  total_loss: 0.05011  loss_cls: 0.01045  loss_box_reg: 0.02795  loss_rpn_cls: 0.0007545  loss_rpn_loc: 0.008767  time: 3.0067  data_time: 0.1066  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:32:53 d2.utils.events]: \u001b[0m eta: 8:06:40  iter: 8339  total_loss: 0.03615  loss_cls: 0.007518  loss_box_reg: 0.0182  loss_rpn_cls: 0.0005642  loss_rpn_loc: 0.007111  time: 3.0068  data_time: 0.0966  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:33:53 d2.utils.events]: \u001b[0m eta: 8:06:05  iter: 8359  total_loss: 0.04603  loss_cls: 0.008983  loss_box_reg: 0.02644  loss_rpn_cls: 0.0007046  loss_rpn_loc: 0.01005  time: 3.0067  data_time: 0.1089  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:34:52 d2.utils.events]: \u001b[0m eta: 8:05:04  iter: 8379  total_loss: 0.03985  loss_cls: 0.008466  loss_box_reg: 0.02122  loss_rpn_cls: 0.0007437  loss_rpn_loc: 0.006667  time: 3.0066  data_time: 0.0876  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:35:51 d2.utils.events]: \u001b[0m eta: 8:03:46  iter: 8399  total_loss: 0.04098  loss_cls: 0.008753  loss_box_reg: 0.0246  loss_rpn_cls: 0.0007327  loss_rpn_loc: 0.007838  time: 3.0065  data_time: 0.0926  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:36:52 d2.utils.events]: \u001b[0m eta: 8:03:21  iter: 8419  total_loss: 0.04017  loss_cls: 0.008557  loss_box_reg: 0.02309  loss_rpn_cls: 0.0009425  loss_rpn_loc: 0.00884  time: 3.0065  data_time: 0.1012  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:37:54 d2.utils.events]: \u001b[0m eta: 8:02:51  iter: 8439  total_loss: 0.04518  loss_cls: 0.01098  loss_box_reg: 0.02597  loss_rpn_cls: 0.0005414  loss_rpn_loc: 0.008969  time: 3.0067  data_time: 0.1131  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:38:55 d2.utils.events]: \u001b[0m eta: 8:01:37  iter: 8459  total_loss: 0.04349  loss_cls: 0.01116  loss_box_reg: 0.0232  loss_rpn_cls: 0.0007649  loss_rpn_loc: 0.008829  time: 3.0068  data_time: 0.0983  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:39:56 d2.utils.events]: \u001b[0m eta: 7:59:52  iter: 8479  total_loss: 0.04802  loss_cls: 0.009352  loss_box_reg: 0.03366  loss_rpn_cls: 0.001185  loss_rpn_loc: 0.01199  time: 3.0069  data_time: 0.0843  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:40:58 d2.utils.events]: \u001b[0m eta: 7:58:52  iter: 8499  total_loss: 0.04087  loss_cls: 0.008227  loss_box_reg: 0.02087  loss_rpn_cls: 0.001042  loss_rpn_loc: 0.009245  time: 3.0072  data_time: 0.1059  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:41:59 d2.utils.events]: \u001b[0m eta: 7:57:36  iter: 8519  total_loss: 0.04165  loss_cls: 0.008177  loss_box_reg: 0.02448  loss_rpn_cls: 0.0006286  loss_rpn_loc: 0.006743  time: 3.0073  data_time: 0.1090  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:42:59 d2.utils.events]: \u001b[0m eta: 7:56:36  iter: 8539  total_loss: 0.04618  loss_cls: 0.01099  loss_box_reg: 0.02616  loss_rpn_cls: 0.0011  loss_rpn_loc: 0.01012  time: 3.0073  data_time: 0.0802  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:43:59 d2.utils.events]: \u001b[0m eta: 7:55:39  iter: 8559  total_loss: 0.03829  loss_cls: 0.00885  loss_box_reg: 0.01769  loss_rpn_cls: 0.0006159  loss_rpn_loc: 0.008914  time: 3.0072  data_time: 0.0876  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:45:01 d2.utils.events]: \u001b[0m eta: 7:55:34  iter: 8579  total_loss: 0.04325  loss_cls: 0.009468  loss_box_reg: 0.0236  loss_rpn_cls: 0.0008059  loss_rpn_loc: 0.006798  time: 3.0074  data_time: 0.0806  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:46:06 d2.utils.events]: \u001b[0m eta: 7:55:14  iter: 8599  total_loss: 0.04222  loss_cls: 0.007464  loss_box_reg: 0.01891  loss_rpn_cls: 0.001002  loss_rpn_loc: 0.008802  time: 3.0080  data_time: 0.1205  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:47:05 d2.utils.events]: \u001b[0m eta: 7:53:45  iter: 8619  total_loss: 0.05563  loss_cls: 0.01149  loss_box_reg: 0.03307  loss_rpn_cls: 0.000918  loss_rpn_loc: 0.01067  time: 3.0079  data_time: 0.1297  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:48:05 d2.utils.events]: \u001b[0m eta: 7:53:00  iter: 8639  total_loss: 0.03354  loss_cls: 0.00708  loss_box_reg: 0.01894  loss_rpn_cls: 0.000641  loss_rpn_loc: 0.007177  time: 3.0079  data_time: 0.1082  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:49:06 d2.utils.events]: \u001b[0m eta: 7:51:40  iter: 8659  total_loss: 0.04621  loss_cls: 0.009379  loss_box_reg: 0.02365  loss_rpn_cls: 0.0009068  loss_rpn_loc: 0.01127  time: 3.0080  data_time: 0.1102  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:50:08 d2.utils.events]: \u001b[0m eta: 7:50:28  iter: 8679  total_loss: 0.04303  loss_cls: 0.01033  loss_box_reg: 0.02225  loss_rpn_cls: 0.0008193  loss_rpn_loc: 0.007956  time: 3.0081  data_time: 0.1013  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:51:08 d2.utils.events]: \u001b[0m eta: 7:49:13  iter: 8699  total_loss: 0.03587  loss_cls: 0.009288  loss_box_reg: 0.02122  loss_rpn_cls: 0.0004881  loss_rpn_loc: 0.006286  time: 3.0081  data_time: 0.1163  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:52:08 d2.utils.events]: \u001b[0m eta: 7:48:26  iter: 8719  total_loss: 0.04684  loss_cls: 0.007543  loss_box_reg: 0.02242  loss_rpn_cls: 0.0009346  loss_rpn_loc: 0.00899  time: 3.0081  data_time: 0.1043  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:53:09 d2.utils.events]: \u001b[0m eta: 7:47:26  iter: 8739  total_loss: 0.04502  loss_cls: 0.009086  loss_box_reg: 0.02543  loss_rpn_cls: 0.0006294  loss_rpn_loc: 0.008814  time: 3.0083  data_time: 0.0826  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:54:09 d2.utils.events]: \u001b[0m eta: 7:46:25  iter: 8759  total_loss: 0.04288  loss_cls: 0.009945  loss_box_reg: 0.02337  loss_rpn_cls: 0.0006769  loss_rpn_loc: 0.007144  time: 3.0082  data_time: 0.1010  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:55:10 d2.utils.events]: \u001b[0m eta: 7:45:25  iter: 8779  total_loss: 0.03574  loss_cls: 0.005925  loss_box_reg: 0.01887  loss_rpn_cls: 0.0005885  loss_rpn_loc: 0.006272  time: 3.0083  data_time: 0.1356  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:56:09 d2.utils.events]: \u001b[0m eta: 7:43:38  iter: 8799  total_loss: 0.04127  loss_cls: 0.01059  loss_box_reg: 0.02239  loss_rpn_cls: 0.0009881  loss_rpn_loc: 0.008239  time: 3.0081  data_time: 0.1007  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:57:08 d2.utils.events]: \u001b[0m eta: 7:42:38  iter: 8819  total_loss: 0.0468  loss_cls: 0.009989  loss_box_reg: 0.02759  loss_rpn_cls: 0.0008178  loss_rpn_loc: 0.009278  time: 3.0081  data_time: 0.1060  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:58:10 d2.utils.events]: \u001b[0m eta: 7:42:26  iter: 8839  total_loss: 0.03244  loss_cls: 0.007197  loss_box_reg: 0.01597  loss_rpn_cls: 0.0003379  loss_rpn_loc: 0.005061  time: 3.0082  data_time: 0.0835  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 02:59:11 d2.utils.events]: \u001b[0m eta: 7:41:09  iter: 8859  total_loss: 0.04058  loss_cls: 0.008913  loss_box_reg: 0.02087  loss_rpn_cls: 0.0009144  loss_rpn_loc: 0.009241  time: 3.0083  data_time: 0.1051  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:00:12 d2.utils.events]: \u001b[0m eta: 7:39:47  iter: 8879  total_loss: 0.03454  loss_cls: 0.006157  loss_box_reg: 0.01572  loss_rpn_cls: 0.0005433  loss_rpn_loc: 0.00616  time: 3.0084  data_time: 0.0857  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:01:12 d2.utils.events]: \u001b[0m eta: 7:38:36  iter: 8899  total_loss: 0.04934  loss_cls: 0.01214  loss_box_reg: 0.02613  loss_rpn_cls: 0.0006215  loss_rpn_loc: 0.01049  time: 3.0084  data_time: 0.0993  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:02:14 d2.utils.events]: \u001b[0m eta: 7:38:06  iter: 8919  total_loss: 0.04707  loss_cls: 0.009473  loss_box_reg: 0.02411  loss_rpn_cls: 0.0008367  loss_rpn_loc: 0.01037  time: 3.0086  data_time: 0.1079  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:03:14 d2.utils.events]: \u001b[0m eta: 7:37:19  iter: 8939  total_loss: 0.0425  loss_cls: 0.008642  loss_box_reg: 0.02309  loss_rpn_cls: 0.001062  loss_rpn_loc: 0.01021  time: 3.0086  data_time: 0.1146  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:04:14 d2.utils.events]: \u001b[0m eta: 7:35:14  iter: 8959  total_loss: 0.04545  loss_cls: 0.01043  loss_box_reg: 0.02695  loss_rpn_cls: 0.0006272  loss_rpn_loc: 0.008019  time: 3.0086  data_time: 0.1053  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:05:17 d2.utils.events]: \u001b[0m eta: 7:35:25  iter: 8979  total_loss: 0.04112  loss_cls: 0.009057  loss_box_reg: 0.02046  loss_rpn_cls: 0.0005824  loss_rpn_loc: 0.007592  time: 3.0088  data_time: 0.1106  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:06:19 fvcore.common.checkpoint]: \u001b[0mSaving checkpoint to /content/gdrive/MyDrive/fsdet-v/model_0008999.pth\n",
            "\u001b[32m[07/29 03:06:22 d2.utils.events]: \u001b[0m eta: 7:33:34  iter: 8999  total_loss: 0.04594  loss_cls: 0.008742  loss_box_reg: 0.02401  loss_rpn_cls: 0.001001  loss_rpn_loc: 0.009597  time: 3.0091  data_time: 0.1525  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:07:23 d2.utils.events]: \u001b[0m eta: 7:32:26  iter: 9019  total_loss: 0.03914  loss_cls: 0.00921  loss_box_reg: 0.02405  loss_rpn_cls: 0.0006291  loss_rpn_loc: 0.007368  time: 3.0092  data_time: 0.1190  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:08:23 d2.utils.events]: \u001b[0m eta: 7:32:20  iter: 9039  total_loss: 0.04274  loss_cls: 0.009055  loss_box_reg: 0.02713  loss_rpn_cls: 0.0006311  loss_rpn_loc: 0.008389  time: 3.0092  data_time: 0.0885  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:09:25 d2.utils.events]: \u001b[0m eta: 7:31:07  iter: 9059  total_loss: 0.04037  loss_cls: 0.009137  loss_box_reg: 0.02666  loss_rpn_cls: 0.000696  loss_rpn_loc: 0.007558  time: 3.0094  data_time: 0.1291  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:10:28 d2.utils.events]: \u001b[0m eta: 7:30:35  iter: 9079  total_loss: 0.03965  loss_cls: 0.009142  loss_box_reg: 0.02157  loss_rpn_cls: 0.0005715  loss_rpn_loc: 0.007663  time: 3.0097  data_time: 0.0943  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:11:30 d2.utils.events]: \u001b[0m eta: 7:29:39  iter: 9099  total_loss: 0.03863  loss_cls: 0.008369  loss_box_reg: 0.0199  loss_rpn_cls: 0.0005787  loss_rpn_loc: 0.007975  time: 3.0099  data_time: 0.0907  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:12:30 d2.utils.events]: \u001b[0m eta: 7:28:27  iter: 9119  total_loss: 0.04556  loss_cls: 0.009379  loss_box_reg: 0.02662  loss_rpn_cls: 0.0006546  loss_rpn_loc: 0.008277  time: 3.0098  data_time: 0.0991  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:13:28 d2.utils.events]: \u001b[0m eta: 7:27:27  iter: 9139  total_loss: 0.03997  loss_cls: 0.007765  loss_box_reg: 0.02192  loss_rpn_cls: 0.0007251  loss_rpn_loc: 0.008638  time: 3.0097  data_time: 0.1000  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:14:25 d2.utils.events]: \u001b[0m eta: 7:26:13  iter: 9159  total_loss: 0.03393  loss_cls: 0.007718  loss_box_reg: 0.01832  loss_rpn_cls: 0.0005141  loss_rpn_loc: 0.006971  time: 3.0094  data_time: 0.1068  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:15:27 d2.utils.events]: \u001b[0m eta: 7:24:52  iter: 9179  total_loss: 0.04669  loss_cls: 0.008989  loss_box_reg: 0.02204  loss_rpn_cls: 0.0007719  loss_rpn_loc: 0.007546  time: 3.0095  data_time: 0.1131  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:16:28 d2.utils.events]: \u001b[0m eta: 7:24:03  iter: 9199  total_loss: 0.04909  loss_cls: 0.009709  loss_box_reg: 0.0278  loss_rpn_cls: 0.0004944  loss_rpn_loc: 0.007675  time: 3.0096  data_time: 0.1095  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:17:30 d2.utils.events]: \u001b[0m eta: 7:22:29  iter: 9219  total_loss: 0.03766  loss_cls: 0.007484  loss_box_reg: 0.01892  loss_rpn_cls: 0.0005282  loss_rpn_loc: 0.008178  time: 3.0098  data_time: 0.1100  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:18:33 d2.utils.events]: \u001b[0m eta: 7:21:35  iter: 9239  total_loss: 0.04239  loss_cls: 0.00841  loss_box_reg: 0.0256  loss_rpn_cls: 0.0004849  loss_rpn_loc: 0.007962  time: 3.0101  data_time: 0.0936  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:19:35 d2.utils.events]: \u001b[0m eta: 7:21:01  iter: 9259  total_loss: 0.04762  loss_cls: 0.009241  loss_box_reg: 0.02644  loss_rpn_cls: 0.0007805  loss_rpn_loc: 0.009227  time: 3.0103  data_time: 0.1150  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:20:36 d2.utils.events]: \u001b[0m eta: 7:20:07  iter: 9279  total_loss: 0.04131  loss_cls: 0.008938  loss_box_reg: 0.02078  loss_rpn_cls: 0.0008599  loss_rpn_loc: 0.01011  time: 3.0104  data_time: 0.0820  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:21:36 d2.utils.events]: \u001b[0m eta: 7:19:03  iter: 9299  total_loss: 0.04081  loss_cls: 0.009236  loss_box_reg: 0.02407  loss_rpn_cls: 0.0006801  loss_rpn_loc: 0.007833  time: 3.0104  data_time: 0.1130  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:22:38 d2.utils.events]: \u001b[0m eta: 7:18:09  iter: 9319  total_loss: 0.03796  loss_cls: 0.007373  loss_box_reg: 0.02236  loss_rpn_cls: 0.000725  loss_rpn_loc: 0.00788  time: 3.0105  data_time: 0.0953  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:23:41 d2.utils.events]: \u001b[0m eta: 7:17:22  iter: 9339  total_loss: 0.03656  loss_cls: 0.007437  loss_box_reg: 0.01908  loss_rpn_cls: 0.0008868  loss_rpn_loc: 0.008563  time: 3.0109  data_time: 0.1096  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:24:40 d2.utils.events]: \u001b[0m eta: 7:16:13  iter: 9359  total_loss: 0.04203  loss_cls: 0.008822  loss_box_reg: 0.02042  loss_rpn_cls: 0.00062  loss_rpn_loc: 0.009455  time: 3.0107  data_time: 0.1075  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:25:40 d2.utils.events]: \u001b[0m eta: 7:15:18  iter: 9379  total_loss: 0.04551  loss_cls: 0.009158  loss_box_reg: 0.02489  loss_rpn_cls: 0.000679  loss_rpn_loc: 0.006811  time: 3.0107  data_time: 0.0941  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:26:41 d2.utils.events]: \u001b[0m eta: 7:14:27  iter: 9399  total_loss: 0.03558  loss_cls: 0.00603  loss_box_reg: 0.01684  loss_rpn_cls: 0.0008894  loss_rpn_loc: 0.008254  time: 3.0107  data_time: 0.1273  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:27:41 d2.utils.events]: \u001b[0m eta: 7:13:08  iter: 9419  total_loss: 0.03861  loss_cls: 0.00916  loss_box_reg: 0.021  loss_rpn_cls: 0.0007805  loss_rpn_loc: 0.007957  time: 3.0107  data_time: 0.1712  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:28:39 d2.utils.events]: \u001b[0m eta: 7:11:59  iter: 9439  total_loss: 0.04247  loss_cls: 0.008608  loss_box_reg: 0.0255  loss_rpn_cls: 0.0005902  loss_rpn_loc: 0.006757  time: 3.0105  data_time: 0.1191  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:29:40 d2.utils.events]: \u001b[0m eta: 7:10:58  iter: 9459  total_loss: 0.04686  loss_cls: 0.00844  loss_box_reg: 0.02627  loss_rpn_cls: 0.0007588  loss_rpn_loc: 0.008859  time: 3.0106  data_time: 0.1004  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:30:42 d2.utils.events]: \u001b[0m eta: 7:09:55  iter: 9479  total_loss: 0.04088  loss_cls: 0.008816  loss_box_reg: 0.0235  loss_rpn_cls: 0.000896  loss_rpn_loc: 0.008894  time: 3.0108  data_time: 0.0952  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:31:43 d2.utils.events]: \u001b[0m eta: 7:08:57  iter: 9499  total_loss: 0.04234  loss_cls: 0.008282  loss_box_reg: 0.02153  loss_rpn_cls: 0.0004579  loss_rpn_loc: 0.009238  time: 3.0108  data_time: 0.0977  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:32:42 d2.utils.events]: \u001b[0m eta: 7:07:54  iter: 9519  total_loss: 0.0433  loss_cls: 0.009264  loss_box_reg: 0.02412  loss_rpn_cls: 0.0008388  loss_rpn_loc: 0.007462  time: 3.0107  data_time: 0.0815  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:33:44 d2.utils.events]: \u001b[0m eta: 7:06:56  iter: 9539  total_loss: 0.03763  loss_cls: 0.009064  loss_box_reg: 0.01801  loss_rpn_cls: 0.0008955  loss_rpn_loc: 0.009484  time: 3.0109  data_time: 0.0924  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:34:46 d2.utils.events]: \u001b[0m eta: 7:06:02  iter: 9559  total_loss: 0.04465  loss_cls: 0.008785  loss_box_reg: 0.0282  loss_rpn_cls: 0.0007391  loss_rpn_loc: 0.008902  time: 3.0111  data_time: 0.1086  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:35:45 d2.utils.events]: \u001b[0m eta: 7:04:59  iter: 9579  total_loss: 0.04164  loss_cls: 0.007612  loss_box_reg: 0.02289  loss_rpn_cls: 0.0005854  loss_rpn_loc: 0.006678  time: 3.0110  data_time: 0.0906  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:36:46 d2.utils.events]: \u001b[0m eta: 7:03:44  iter: 9599  total_loss: 0.03927  loss_cls: 0.008889  loss_box_reg: 0.01866  loss_rpn_cls: 0.0007602  loss_rpn_loc: 0.008602  time: 3.0111  data_time: 0.1060  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:37:47 d2.utils.events]: \u001b[0m eta: 7:02:51  iter: 9619  total_loss: 0.03248  loss_cls: 0.007292  loss_box_reg: 0.01633  loss_rpn_cls: 0.0007059  loss_rpn_loc: 0.007725  time: 3.0112  data_time: 0.0996  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:38:47 d2.utils.events]: \u001b[0m eta: 7:01:35  iter: 9639  total_loss: 0.03424  loss_cls: 0.009609  loss_box_reg: 0.02182  loss_rpn_cls: 0.0005447  loss_rpn_loc: 0.006756  time: 3.0111  data_time: 0.1021  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:39:49 d2.utils.events]: \u001b[0m eta: 7:00:49  iter: 9659  total_loss: 0.04091  loss_cls: 0.007821  loss_box_reg: 0.02187  loss_rpn_cls: 0.001047  loss_rpn_loc: 0.009174  time: 3.0113  data_time: 0.1165  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:40:49 d2.utils.events]: \u001b[0m eta: 6:59:49  iter: 9679  total_loss: 0.04545  loss_cls: 0.01067  loss_box_reg: 0.0288  loss_rpn_cls: 0.0006725  loss_rpn_loc: 0.007048  time: 3.0113  data_time: 0.1044  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:41:48 d2.utils.events]: \u001b[0m eta: 6:58:48  iter: 9699  total_loss: 0.04057  loss_cls: 0.008772  loss_box_reg: 0.02475  loss_rpn_cls: 0.0006596  loss_rpn_loc: 0.006388  time: 3.0112  data_time: 0.1039  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:42:50 d2.utils.events]: \u001b[0m eta: 6:57:57  iter: 9719  total_loss: 0.0344  loss_cls: 0.007104  loss_box_reg: 0.02101  loss_rpn_cls: 0.0007974  loss_rpn_loc: 0.007445  time: 3.0113  data_time: 0.0911  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:43:51 d2.utils.events]: \u001b[0m eta: 6:57:02  iter: 9739  total_loss: 0.0438  loss_cls: 0.00886  loss_box_reg: 0.02401  loss_rpn_cls: 0.0006129  loss_rpn_loc: 0.00895  time: 3.0114  data_time: 0.0904  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:44:53 d2.utils.events]: \u001b[0m eta: 6:56:05  iter: 9759  total_loss: 0.03543  loss_cls: 0.007947  loss_box_reg: 0.01931  loss_rpn_cls: 0.0004905  loss_rpn_loc: 0.00771  time: 3.0116  data_time: 0.1109  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:45:54 d2.utils.events]: \u001b[0m eta: 6:54:57  iter: 9779  total_loss: 0.04727  loss_cls: 0.01121  loss_box_reg: 0.02639  loss_rpn_cls: 0.000505  loss_rpn_loc: 0.008017  time: 3.0116  data_time: 0.0998  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:46:52 d2.utils.events]: \u001b[0m eta: 6:53:55  iter: 9799  total_loss: 0.03673  loss_cls: 0.008672  loss_box_reg: 0.02028  loss_rpn_cls: 0.0005384  loss_rpn_loc: 0.005613  time: 3.0115  data_time: 0.1137  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:47:51 d2.utils.events]: \u001b[0m eta: 6:52:52  iter: 9819  total_loss: 0.0432  loss_cls: 0.007491  loss_box_reg: 0.02121  loss_rpn_cls: 0.0006906  loss_rpn_loc: 0.007257  time: 3.0113  data_time: 0.0940  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:48:49 d2.utils.events]: \u001b[0m eta: 6:51:37  iter: 9839  total_loss: 0.04433  loss_cls: 0.008189  loss_box_reg: 0.02757  loss_rpn_cls: 0.0006358  loss_rpn_loc: 0.008411  time: 3.0111  data_time: 0.0949  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:49:48 d2.utils.events]: \u001b[0m eta: 6:50:24  iter: 9859  total_loss: 0.04928  loss_cls: 0.009607  loss_box_reg: 0.02715  loss_rpn_cls: 0.000691  loss_rpn_loc: 0.007907  time: 3.0109  data_time: 0.1125  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:50:48 d2.utils.events]: \u001b[0m eta: 6:49:19  iter: 9879  total_loss: 0.03385  loss_cls: 0.007407  loss_box_reg: 0.01919  loss_rpn_cls: 0.0005823  loss_rpn_loc: 0.006319  time: 3.0109  data_time: 0.1082  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:51:46 d2.utils.events]: \u001b[0m eta: 6:48:00  iter: 9899  total_loss: 0.05041  loss_cls: 0.01095  loss_box_reg: 0.02786  loss_rpn_cls: 0.0006404  loss_rpn_loc: 0.008428  time: 3.0107  data_time: 0.1026  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:52:48 d2.utils.events]: \u001b[0m eta: 6:46:57  iter: 9919  total_loss: 0.04053  loss_cls: 0.007207  loss_box_reg: 0.02246  loss_rpn_cls: 0.000876  loss_rpn_loc: 0.01065  time: 3.0109  data_time: 0.1163  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:53:49 d2.utils.events]: \u001b[0m eta: 6:45:59  iter: 9939  total_loss: 0.03299  loss_cls: 0.007803  loss_box_reg: 0.01937  loss_rpn_cls: 0.0006129  loss_rpn_loc: 0.007879  time: 3.0110  data_time: 0.1061  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:54:51 d2.utils.events]: \u001b[0m eta: 6:45:09  iter: 9959  total_loss: 0.03208  loss_cls: 0.007514  loss_box_reg: 0.01678  loss_rpn_cls: 0.0004619  loss_rpn_loc: 0.005693  time: 3.0112  data_time: 0.1647  lr: 0.02  max_mem: 12497M\n",
            "\u001b[32m[07/29 03:55:54 d2.utils.events]: \u001b[0m eta: 6:44:12  iter: 9979  total_loss: 0.03722  loss_cls: 0.007759  loss_box_reg: 0.01901  loss_rpn_cls: 0.0006739  loss_rpn_loc: 0.006714  time: 3.0114  data_time: 0.0899  lr: 0.02  max_mem: 12497M\n"
          ]
        }
      ],
      "source": [
        "!python3 -m tools.train_net \\\n",
        "    --num-gpus 1 \\\n",
        "    --config-file configs/Custom-Bear/base_training_cfg.yaml "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBG69BcTLAP2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "d881c225-f940-4391-e733-d15f8694d877"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ],
      "source": [
        "assert False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqfv_soPCeHZ"
      },
      "outputs": [],
      "source": [
        "#!cp checkpoints/coco/faster_rcnn/faster_rcnn_R_101_FPN_ft_all_1shot/model_0002999.pth /content/gdrive/MyDrive/fsdet-v/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh1vkESwYvjo"
      },
      "source": [
        "### Model testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSUHiCcSaUPq"
      },
      "outputs": [],
      "source": [
        "!cp /content/gdrive/MyDrive/fsdet-v/jsons/datasplit/5k.json datasets/cocosplit/datasplit/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4WDCln2K_st"
      },
      "outputs": [],
      "source": [
        "# Download images of the validation set - 5k.json\n",
        "%cd datasets/cocosplit/datasplit\n",
        "!cp ../download_from_jsons.sh ./\n",
        "!./download_from_jsons.sh\n",
        "!wget -i links.txt -P ../../coco/val2014"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxlYS814YtjR"
      },
      "outputs": [],
      "source": [
        "!python3 -m tools.test_net --num-gpus 1 \\\n",
        "  --config-file configs/COCO-detection/faster_rcnn_R_101_FPN_ft_all_1shot.yaml \\\n",
        "  --eval-only \\\n",
        "  --opts MODEL.WEIGHTS checkpoints/coco/faster_rcnn/faster_rcnn_R_101_FPN_ft_all_1shot/model_0002999.pth "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Custom_Bear.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}